{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Attention_Solution_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwPL0hIlGKoA"
      },
      "source": [
        "# <font color='red'>**Sequence to sequence implementation**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nYHE_1ck2az"
      },
      "source": [
        "**There will be some functions that start with the word \"grader\" ex: grader_check_encoder(), grader_check_attention(), grader_onestepdecoder() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**\n",
        "\n",
        "**Note 1:**  There are many blogs on the attention mechanisum which might be misleading you,\n",
        " so do read the references completly and after that only please check the internet.\n",
        " The best things is to read the research papers and try to implement it on your own. \n",
        "\n",
        "**Note 2:** To complete this assignment, the reference that are mentioned will be enough.\n",
        "\n",
        "**Note 3:** If you are starting this assignment, you might have completed minimum of 20 assignment.\n",
        " If  you are still not able to implement this algorithm you might have rushed in the previous assignments \n",
        "with out learning much and didn't spend your time productively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyfZo8fmLOec"
      },
      "source": [
        "## Task -1: Simple Encoder and Decoder\n",
        "Implement simple Encoder-Decoder model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvNSZXNkkOkO"
      },
      "source": [
        "1. Download the **Italian** to **English** translation dataset from <a href=\"http://www.manythings.org/anki/ita-eng.zip\">here</a>\n",
        "\n",
        "2. You will find **ita.txt** file in that ZIP, \n",
        "you can read that data using python and preprocess that data this way only: \n",
        "<img src='https://i.imgur.com/z0j79Jf.png'>    \n",
        "    \n",
        "3. You have to implement a simple Encoder and Decoder architecture  \n",
        "\n",
        "4. Use BLEU score as metric to evaluate your model. You can use any loss function you need.\n",
        "\n",
        "5. You have to use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
        "\n",
        "6.  a. Check the reference notebook <br>\n",
        "    b. <a href=\"https://medium.com/analytics-vidhya/understand-sequence-to-sequence-models-in-a-more-intuitive-way-1d517d8795bb\">Resource 2</a>\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k_AlAuKJqVA"
      },
      "source": [
        "<font color='blue'>**Load the data**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T13:14:31.538693Z",
          "iopub.execute_input": "2021-08-28T13:14:31.539043Z",
          "iopub.status.idle": "2021-08-28T13:14:35.774834Z",
          "shell.execute_reply.started": "2021-08-28T13:14:31.539010Z",
          "shell.execute_reply": "2021-08-28T13:14:35.773905Z"
        },
        "trusted": true,
        "id": "6j2hUUI9NwD7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# import seaborn as sns\n",
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import*\n",
        "import os\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU80Ao-AGaob",
        "execution": {
          "iopub.status.busy": "2021-08-28T13:14:35.776535Z",
          "iopub.execute_input": "2021-08-28T13:14:35.776894Z",
          "iopub.status.idle": "2021-08-28T13:14:37.124395Z",
          "shell.execute_reply.started": "2021-08-28T13:14:35.776855Z",
          "shell.execute_reply": "2021-08-28T13:14:37.123457Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "75d1ebb5-a49c-494e-ce0a-091b29809dfc"
      },
      "source": [
        "with open('/content/drive/MyDrive/Seq_Seq_attention/ita.txt', 'r', encoding=\"utf8\") as f:\n",
        "    eng=[]\n",
        "    ita=[]\n",
        "    for i in f.readlines():\n",
        "        eng.append(i.split(\"\\t\")[0])\n",
        "        ita.append(i.split(\"\\t\")[1])\n",
        "data = pd.DataFrame(data=list(zip(eng, ita)), columns=['english','italian'])\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(352040, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corri!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corra!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Correte!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  english   italian\n",
              "0     Hi.     Ciao!\n",
              "1     Hi.     Ciao.\n",
              "2    Run!    Corri!\n",
              "3    Run!    Corra!\n",
              "4    Run!  Correte!"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmGWTdRmKRph"
      },
      "source": [
        "<font color='blue'>**Preprocess data**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QqElB_nKZos",
        "execution": {
          "iopub.status.busy": "2021-08-28T13:14:37.126414Z",
          "iopub.execute_input": "2021-08-28T13:14:37.126692Z",
          "iopub.status.idle": "2021-08-28T13:14:54.683577Z",
          "shell.execute_reply.started": "2021-08-28T13:14:37.126666Z",
          "shell.execute_reply": "2021-08-28T13:14:54.682600Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "62c7d563-9451-493f-ddf4-de06f490997e"
      },
      "source": [
        "def decontractions(phrase):\n",
        "    \"\"\"decontracted takes text and convert contractions into natural form.\n",
        "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "\n",
        "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
        "\n",
        "    return phrase\n",
        "\n",
        "def preprocess(text):\n",
        "    # convert all the text into lower letters\n",
        "    # use this function to remove the contractions: https://gist.github.com/anandborad/d410a49a493b56dace4f814ab5325bbd\n",
        "    # remove all the spacial characters: except space ' '\n",
        "    text = text.lower()\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
        "    return text\n",
        "\n",
        "def preprocess_ita(text):\n",
        "    # convert all the text into lower letters\n",
        "    # remove the words betweent brakets ()\n",
        "    # remove these characters: {'$', ')', '?', '\"', '’', '.',  '°', '!', ';', '/', \"'\", '€', '%', ':', ',', '('}\n",
        "    # replace these spl characters with space: '\\u200b', '\\xa0', '-', '/'\n",
        "    # we have found these characters after observing the data points, feel free to explore more and see if you can do find more\n",
        "    # you are free to do more proprocessing\n",
        "    # note that the model will learn better with better preprocessed data \n",
        "    \n",
        "    text = text.lower()\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[$)\\?\"’.°!;\\'€%:,(/]', '', text)\n",
        "    text = re.sub('\\u200b', ' ', text)\n",
        "    text = re.sub('\\xa0', ' ', text)\n",
        "    text = re.sub('-', ' ', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "data['english'] = data['english'].apply(preprocess)\n",
        "data['italian'] = data['italian'].apply(preprocess_ita)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi</td>\n",
              "      <td>ciao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hi</td>\n",
              "      <td>ciao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run</td>\n",
              "      <td>corri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>run</td>\n",
              "      <td>corra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>run</td>\n",
              "      <td>correte</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  english  italian\n",
              "0      hi     ciao\n",
              "1      hi     ciao\n",
              "2     run    corri\n",
              "3     run    corra\n",
              "4     run  correte"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T13:14:54.685284Z",
          "iopub.execute_input": "2021-08-28T13:14:54.685619Z",
          "iopub.status.idle": "2021-08-28T13:14:56.691203Z",
          "shell.execute_reply.started": "2021-08-28T13:14:54.685584Z",
          "shell.execute_reply": "2021-08-28T13:14:56.690341Z"
        },
        "trusted": true,
        "id": "1LDetg8iNwEC"
      },
      "source": [
        "ita_lengths = data['italian'].str.split().apply(len)\n",
        "eng_lengths = data['english'].str.split().apply(len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T13:14:56.692453Z",
          "iopub.execute_input": "2021-08-28T13:14:56.692857Z",
          "iopub.status.idle": "2021-08-28T13:14:56.786990Z",
          "shell.execute_reply.started": "2021-08-28T13:14:56.692813Z",
          "shell.execute_reply": "2021-08-28T13:14:56.786223Z"
        },
        "trusted": true,
        "id": "JavwURVXNwEC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a42250a0-eb34-4755-b07d-034c2d07be22"
      },
      "source": [
        "for i in range(0,101,10):\n",
        "    print(i,np.percentile(ita_lengths, i))\n",
        "for i in range(90,101):\n",
        "    print(i,np.percentile(ita_lengths, i))\n",
        "for i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n",
        "    print(i,np.percentile(ita_lengths, i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.0\n",
            "10 3.0\n",
            "20 4.0\n",
            "30 4.0\n",
            "40 5.0\n",
            "50 5.0\n",
            "60 6.0\n",
            "70 6.0\n",
            "80 7.0\n",
            "90 8.0\n",
            "100 92.0\n",
            "90 8.0\n",
            "91 8.0\n",
            "92 8.0\n",
            "93 9.0\n",
            "94 9.0\n",
            "95 9.0\n",
            "96 10.0\n",
            "97 10.0\n",
            "98 11.0\n",
            "99 12.0\n",
            "100 92.0\n",
            "99.1 12.0\n",
            "99.2 12.0\n",
            "99.3 13.0\n",
            "99.4 13.0\n",
            "99.5 13.0\n",
            "99.6 14.0\n",
            "99.7 15.0\n",
            "99.8 16.0\n",
            "99.9 22.0\n",
            "100 92.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T13:14:56.788295Z",
          "iopub.execute_input": "2021-08-28T13:14:56.788622Z",
          "iopub.status.idle": "2021-08-28T13:14:56.860275Z",
          "shell.execute_reply.started": "2021-08-28T13:14:56.788585Z",
          "shell.execute_reply": "2021-08-28T13:14:56.859496Z"
        },
        "trusted": true,
        "id": "TaplW35nNwED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b23490c-6c8f-434c-a3d2-5b7879c12eb5"
      },
      "source": [
        "for i in range(0,101,10):\n",
        "    print(i,np.percentile(eng_lengths, i))\n",
        "for i in range(90,101):\n",
        "    print(i,np.percentile(eng_lengths, i))\n",
        "for i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n",
        "    print(i,np.percentile(eng_lengths, i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.0\n",
            "10 4.0\n",
            "20 4.0\n",
            "30 5.0\n",
            "40 5.0\n",
            "50 6.0\n",
            "60 6.0\n",
            "70 7.0\n",
            "80 7.0\n",
            "90 8.0\n",
            "100 101.0\n",
            "90 8.0\n",
            "91 9.0\n",
            "92 9.0\n",
            "93 9.0\n",
            "94 9.0\n",
            "95 9.0\n",
            "96 10.0\n",
            "97 10.0\n",
            "98 11.0\n",
            "99 12.0\n",
            "100 101.0\n",
            "99.1 12.0\n",
            "99.2 13.0\n",
            "99.3 13.0\n",
            "99.4 13.0\n",
            "99.5 14.0\n",
            "99.6 14.0\n",
            "99.7 15.0\n",
            "99.8 16.0\n",
            "99.9 25.0\n",
            "100 101.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T13:14:56.863174Z",
          "iopub.execute_input": "2021-08-28T13:14:56.863431Z",
          "iopub.status.idle": "2021-08-28T13:14:59.521602Z",
          "shell.execute_reply.started": "2021-08-28T13:14:56.863405Z",
          "shell.execute_reply": "2021-08-28T13:14:59.520759Z"
        },
        "trusted": true,
        "id": "qnZs7PZmNwED",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "ea5315e7-6669-4f8b-95f3-a07a8883abdf"
      },
      "source": [
        "data['italian_len'] = data['italian'].str.split().apply(len)\n",
        "data = data[data['italian_len'] < 20]\n",
        "\n",
        "data['english_len'] = data['english'].str.split().apply(len)\n",
        "data = data[data['english_len'] < 20]\n",
        "\n",
        "data['english_inp'] = '<start> ' + data['english'].astype(str)\n",
        "data['english_out'] = data['english'].astype(str) + ' <end>'\n",
        "\n",
        "data = data.drop(['english','italian_len','english_len'], axis=1)\n",
        "# only for the first sentance add a toke <end> so that we will have <end> in tokenizer\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ciao</td>\n",
              "      <td>&lt;start&gt; hi</td>\n",
              "      <td>hi &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ciao</td>\n",
              "      <td>&lt;start&gt; hi</td>\n",
              "      <td>hi &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>corri</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>corra</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>correte</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   italian  english_inp english_out\n",
              "0     ciao   <start> hi    hi <end>\n",
              "1     ciao   <start> hi    hi <end>\n",
              "2    corri  <start> run   run <end>\n",
              "3    corra  <start> run   run <end>\n",
              "4  correte  <start> run   run <end>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T13:14:59.526677Z",
          "iopub.execute_input": "2021-08-28T13:14:59.528767Z",
          "iopub.status.idle": "2021-08-28T13:14:59.560477Z",
          "shell.execute_reply.started": "2021-08-28T13:14:59.528721Z",
          "shell.execute_reply": "2021-08-28T13:14:59.559706Z"
        },
        "trusted": true,
        "id": "2lvUEaqxNwEE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "cf04b2c6-797a-4e7c-909f-bb377d03b0cb"
      },
      "source": [
        "data.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>238592</th>\n",
              "      <td>era preoccupata vero</td>\n",
              "      <td>&lt;start&gt; you were worried were not you</td>\n",
              "      <td>you were worried were not you &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48044</th>\n",
              "      <td>so che lho fatto</td>\n",
              "      <td>&lt;start&gt; i know i did that</td>\n",
              "      <td>i know i did that &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123387</th>\n",
              "      <td>per favore correggi il mio conto</td>\n",
              "      <td>&lt;start&gt; please correct my bill</td>\n",
              "      <td>please correct my bill &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297582</th>\n",
              "      <td>tom spiegò la situazione a mary</td>\n",
              "      <td>&lt;start&gt; tom explained the situation to mary</td>\n",
              "      <td>tom explained the situation to mary &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>332792</th>\n",
              "      <td>mary è una ragazza con cui è piacevole parlare</td>\n",
              "      <td>&lt;start&gt; mary is a girl who is pleasant to talk...</td>\n",
              "      <td>mary is a girl who is pleasant to talk with &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112251</th>\n",
              "      <td>provate a pensarci</td>\n",
              "      <td>&lt;start&gt; try to think about it</td>\n",
              "      <td>try to think about it &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184716</th>\n",
              "      <td>io sto ascoltando questa band</td>\n",
              "      <td>&lt;start&gt; i am listening to this band</td>\n",
              "      <td>i am listening to this band &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204319</th>\n",
              "      <td>tom accettò linevitabile</td>\n",
              "      <td>&lt;start&gt; tom accepted the inevitable</td>\n",
              "      <td>tom accepted the inevitable &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12245</th>\n",
              "      <td>mi ha mentito</td>\n",
              "      <td>&lt;start&gt; he lied to me</td>\n",
              "      <td>he lied to me &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316662</th>\n",
              "      <td>perché non andate a sedervi al tavolo</td>\n",
              "      <td>&lt;start&gt; why do not you go sit down at the table</td>\n",
              "      <td>why do not you go sit down at the table &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               italian  ...                                        english_out\n",
              "238592                            era preoccupata vero  ...                you were worried were not you <end>\n",
              "48044                                 so che lho fatto  ...                            i know i did that <end>\n",
              "123387                per favore correggi il mio conto  ...                       please correct my bill <end>\n",
              "297582                 tom spiegò la situazione a mary  ...          tom explained the situation to mary <end>\n",
              "332792  mary è una ragazza con cui è piacevole parlare  ...  mary is a girl who is pleasant to talk with <end>\n",
              "112251                              provate a pensarci  ...                        try to think about it <end>\n",
              "184716                   io sto ascoltando questa band  ...                  i am listening to this band <end>\n",
              "204319                        tom accettò linevitabile  ...                  tom accepted the inevitable <end>\n",
              "12245                                    mi ha mentito  ...                                he lied to me <end>\n",
              "316662           perché non andate a sedervi al tavolo  ...      why do not you go sit down at the table <end>\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T13:14:59.564552Z",
          "iopub.execute_input": "2021-08-28T13:14:59.566543Z",
          "iopub.status.idle": "2021-08-28T13:15:00.203580Z",
          "shell.execute_reply.started": "2021-08-28T13:14:59.566503Z",
          "shell.execute_reply": "2021-08-28T13:15:00.202725Z"
        },
        "trusted": true,
        "id": "aG8UBg1KNwEF"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(data, test_size = 0.1, random_state = 0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T13:15:00.206579Z",
          "iopub.execute_input": "2021-08-28T13:15:00.206849Z",
          "iopub.status.idle": "2021-08-28T13:15:00.215130Z",
          "shell.execute_reply.started": "2021-08-28T13:15:00.206822Z",
          "shell.execute_reply": "2021-08-28T13:15:00.214140Z"
        },
        "trusted": true,
        "id": "a2V04F18NwEF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f4512a-b2a7-4376-801a-c6b4cd5118df"
      },
      "source": [
        "print(train.shape, test.shape)\n",
        "# for one sentence we will be adding <end> token so that the tokanizer learns the word <end>\n",
        "# with this we can use only one tokenizer for both encoder output and decoder output\n",
        "train.iloc[0]['english_inp']= str(train.iloc[0]['english_inp'])+' <end>'\n",
        "train.iloc[0]['english_out']= str(train.iloc[0]['english_out'])+' <end>'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(316399, 3) (35156, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T13:15:00.216284Z",
          "iopub.execute_input": "2021-08-28T13:15:00.216709Z",
          "iopub.status.idle": "2021-08-28T13:15:00.231089Z",
          "shell.execute_reply.started": "2021-08-28T13:15:00.216674Z",
          "shell.execute_reply": "2021-08-28T13:15:00.230213Z"
        },
        "trusted": true,
        "id": "3QrSPr7VNwEG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "4014c3d9-c4e6-421a-92b2-00529d8061f1"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9566</th>\n",
              "      <td>liberi tom</td>\n",
              "      <td>&lt;start&gt; set tom free &lt;end&gt;</td>\n",
              "      <td>set tom free &lt;end&gt; &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>333330</th>\n",
              "      <td>tom non sa farsi capire in francese</td>\n",
              "      <td>&lt;start&gt; tom can not make himself understood in...</td>\n",
              "      <td>tom can not make himself understood in french ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256099</th>\n",
              "      <td>penso che mi dovrebbe ascoltare</td>\n",
              "      <td>&lt;start&gt; i think you should listen to me</td>\n",
              "      <td>i think you should listen to me &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340320</th>\n",
              "      <td>penso che faremmo meglio ad aspettare altri tr...</td>\n",
              "      <td>&lt;start&gt; i think we would better wait another t...</td>\n",
              "      <td>i think we would better wait another thirty mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127911</th>\n",
              "      <td>non abbiamo detto niente</td>\n",
              "      <td>&lt;start&gt; we did not say anything</td>\n",
              "      <td>we did not say anything &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  italian  ...                                        english_out\n",
              "9566                                           liberi tom  ...                           set tom free <end> <end>\n",
              "333330                tom non sa farsi capire in francese  ...  tom can not make himself understood in french ...\n",
              "256099                    penso che mi dovrebbe ascoltare  ...              i think you should listen to me <end>\n",
              "340320  penso che faremmo meglio ad aspettare altri tr...  ...  i think we would better wait another thirty mi...\n",
              "127911                           non abbiamo detto niente  ...                      we did not say anything <end>\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T13:15:00.233606Z",
          "iopub.execute_input": "2021-08-28T13:15:00.233851Z",
          "iopub.status.idle": "2021-08-28T13:15:00.244555Z",
          "shell.execute_reply.started": "2021-08-28T13:15:00.233828Z",
          "shell.execute_reply": "2021-08-28T13:15:00.243569Z"
        },
        "trusted": true,
        "id": "H424i0qHNwEH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "fca62622-627f-441c-d6ba-3c7bd63b6bb5"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>148349</th>\n",
              "      <td>non pensi che non abbia provato</td>\n",
              "      <td>&lt;start&gt; do not think i did not try</td>\n",
              "      <td>do not think i did not try &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97165</th>\n",
              "      <td>abbiamo cambiato idea</td>\n",
              "      <td>&lt;start&gt; we changed our minds</td>\n",
              "      <td>we changed our minds &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>333265</th>\n",
              "      <td>quelle persone laggiù stanno parlando in francese</td>\n",
              "      <td>&lt;start&gt; those people over there are speaking f...</td>\n",
              "      <td>those people over there are speaking french &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215475</th>\n",
              "      <td>io voglio costruire una casa qui</td>\n",
              "      <td>&lt;start&gt; i want to build a house here</td>\n",
              "      <td>i want to build a house here &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62024</th>\n",
              "      <td>starò con tom</td>\n",
              "      <td>&lt;start&gt; i will stay with tom</td>\n",
              "      <td>i will stay with tom &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  italian  ...                                        english_out\n",
              "148349                    non pensi che non abbia provato  ...                   do not think i did not try <end>\n",
              "97165                               abbiamo cambiato idea  ...                         we changed our minds <end>\n",
              "333265  quelle persone laggiù stanno parlando in francese  ...  those people over there are speaking french <end>\n",
              "215475                   io voglio costruire una casa qui  ...                 i want to build a house here <end>\n",
              "62024                                       starò con tom  ...                         i will stay with tom <end>\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T13:15:00.246078Z",
          "iopub.execute_input": "2021-08-28T13:15:00.246860Z",
          "iopub.status.idle": "2021-08-28T13:15:05.568283Z",
          "shell.execute_reply.started": "2021-08-28T13:15:00.246822Z",
          "shell.execute_reply": "2021-08-28T13:15:05.566458Z"
        },
        "trusted": true,
        "id": "UT51CPTUNwEH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "8e3d642d-725c-4482-d225-d174b9bc609d"
      },
      "source": [
        "ita_lengths = train['italian'].str.split().apply(len)\n",
        "eng_lengths = train['english_inp'].str.split().apply(len)\n",
        "import seaborn as sns\n",
        "sns.kdeplot(ita_lengths)\n",
        "plt.show()\n",
        "sns.kdeplot(eng_lengths)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T13:15:05.569537Z",
          "iopub.execute_input": "2021-08-28T13:15:05.569881Z",
          "iopub.status.idle": "2021-08-28T13:15:12.992395Z",
          "shell.execute_reply.started": "2021-08-28T13:15:05.569843Z",
          "shell.execute_reply": "2021-08-28T13:15:12.991501Z"
        },
        "trusted": true,
        "id": "7QHqz44BNwEI"
      },
      "source": [
        "tknizer_ita = Tokenizer()\n",
        "tknizer_ita.fit_on_texts(train['italian'].values)\n",
        "tknizer_eng = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
        "tknizer_eng.fit_on_texts(train['english_inp'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T13:15:12.993594Z",
          "iopub.execute_input": "2021-08-28T13:15:12.993926Z",
          "iopub.status.idle": "2021-08-28T13:15:13.001287Z",
          "shell.execute_reply.started": "2021-08-28T13:15:12.993893Z",
          "shell.execute_reply": "2021-08-28T13:15:13.000226Z"
        },
        "trusted": true,
        "id": "Y5ZW8gSZNwEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "444a08b3-63de-494f-d68e-acf759b9fe5b"
      },
      "source": [
        "vocab_size_eng=len(tknizer_eng.word_index.keys())\n",
        "print(vocab_size_eng)\n",
        "vocab_size_ita=len(tknizer_ita.word_index.keys())\n",
        "print(vocab_size_ita)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13363\n",
            "27508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T13:15:13.002921Z",
          "iopub.execute_input": "2021-08-28T13:15:13.003629Z",
          "iopub.status.idle": "2021-08-28T13:15:13.010581Z",
          "shell.execute_reply.started": "2021-08-28T13:15:13.003590Z",
          "shell.execute_reply": "2021-08-28T13:15:13.009680Z"
        },
        "trusted": true,
        "id": "tBpkAPY3NwEJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adecdff1-cedb-4c16-c1f1-34d9f80eed94"
      },
      "source": [
        "tknizer_eng.word_index['<start>'], tknizer_eng.word_index['<end>']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10710)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8RDrP4xKabR"
      },
      "source": [
        "## <font color='blue'>**Implement custom encoder decoder**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A45uc0JILMlV"
      },
      "source": [
        "<font color='blue'>**Encoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cex2XfCLOew",
        "execution": {
          "iopub.status.busy": "2021-08-28T06:24:30.808130Z",
          "iopub.execute_input": "2021-08-28T06:24:30.808889Z",
          "iopub.status.idle": "2021-08-28T06:24:30.819462Z",
          "shell.execute_reply.started": "2021-08-28T06:24:30.808847Z",
          "shell.execute_reply": "2021-08-28T06:24:30.818457Z"
        },
        "trusted": true
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
        "    '''\n",
        "\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "        super().__init__()\n",
        "        self.inp_vocab_size = inp_vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.lstm_size = lstm_size\n",
        "        self.input_length = input_length\n",
        "        #Initialize Embedding layer\n",
        "        self.encoder_embedding = Embedding(input_dim = inp_vocab_size,\n",
        "                                           output_dim = embedding_size,\n",
        "                                           input_length= input_length)\n",
        "        #Intialize Encoder LSTM layer\n",
        "        self.encoder_Lstm = LSTM(lstm_size, return_sequences = True, return_state = True)\n",
        "\n",
        "    def call(self,input_sequence,states):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "          returns -- encoder_output, last time step's hidden and cell state\n",
        "        '''\n",
        "        input_embedding = self.encoder_embedding(input_sequence)\n",
        "        encoder_output_state, encoder_h, encoder_c = self.encoder_Lstm(input_embedding, initial_state = states)\n",
        "        return encoder_output_state, encoder_h, encoder_c\n",
        "\n",
        "    \n",
        "    def initialize_states(self,batch_size):\n",
        "      '''\n",
        "      Given a batch size it will return intial hidden state and intial cell state.\n",
        "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
        "      '''\n",
        "      return [tf.zeros((batch_size, self.lstm_size)), tf.zeros((batch_size, self.lstm_size))]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtbOI3VwLOe0"
      },
      "source": [
        "<font color='orange'>**Grader function - 1**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziSqOgmhLOe1",
        "execution": {
          "iopub.status.busy": "2021-08-28T06:24:38.132607Z",
          "iopub.execute_input": "2021-08-28T06:24:38.132881Z",
          "iopub.status.idle": "2021-08-28T06:24:38.157289Z",
          "shell.execute_reply.started": "2021-08-28T06:24:38.132857Z",
          "shell.execute_reply": "2021-08-28T06:24:38.156566Z"
        },
        "trusted": true,
        "outputId": "a0214312-6ff5-4d29-c8a0-c3fa2465efa7"
      },
      "source": [
        "def grader_check_encoder():\n",
        "    '''\n",
        "        vocab-size: Unique words of the input language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        lstm_size: Number of lstm units,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    vocab_size=10\n",
        "    embedding_size=20\n",
        "    lstm_size=32\n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    #Intialzing encoder \n",
        "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
        "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
        "    #Intializing encoder initial states\n",
        "    initial_state=encoder.initialize_states(batch_size)\n",
        "    \n",
        "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
        "    \n",
        "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
        "    return True\n",
        "print(grader_check_encoder())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "True\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1ES1-sJLOe4",
        "execution": {
          "iopub.status.busy": "2021-08-28T06:24:39.809031Z",
          "iopub.execute_input": "2021-08-28T06:24:39.809352Z",
          "iopub.status.idle": "2021-08-28T06:24:39.817394Z",
          "shell.execute_reply.started": "2021-08-28T06:24:39.809314Z",
          "shell.execute_reply": "2021-08-28T06:24:39.816328Z"
        },
        "trusted": true
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns output sequence\n",
        "    '''\n",
        "\n",
        "    def __init__(self,out_vocab_size,embedding_size,lstm_size,input_length):\n",
        "        super().__init__()\n",
        "        self.out_vocab_size = out_vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.lstm_size = lstm_size\n",
        "        self.input_length = input_length\n",
        "        #Initialize Embedding layer\n",
        "        self.decoder_embedding = Embedding(input_dim = out_vocab_size, \n",
        "                                           output_dim = embedding_size, \n",
        "                                           input_length = input_length)\n",
        "        #Intialize Decoder LSTM layer\n",
        "        self.decoder_LSTM = LSTM(lstm_size, return_sequences = True, return_state = True)\n",
        "\n",
        "    def call(self,input_sequence,initial_states):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to decoder_lstm\n",
        "        \n",
        "          returns -- decoder_output,decoder_final_state_h,decoder_final_state_c\n",
        "        '''\n",
        "        target_embedding = self.decoder_embedding(input_sequence)\n",
        "        decoder_output_state,  decoder_h,  decoder_c = self.decoder_LSTM(target_embedding, \n",
        "                                                                         initial_state = initial_states)\n",
        "        return decoder_output_state, decoder_h, decoder_c\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq-I0SUbLOe8"
      },
      "source": [
        "<font color='orange'>**Grader function - 2**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B0gokgKLOe8",
        "execution": {
          "iopub.status.busy": "2021-08-28T06:24:42.489794Z",
          "iopub.execute_input": "2021-08-28T06:24:42.490115Z",
          "iopub.status.idle": "2021-08-28T06:24:42.517449Z",
          "shell.execute_reply.started": "2021-08-28T06:24:42.490085Z",
          "shell.execute_reply": "2021-08-28T06:24:42.516362Z"
        },
        "trusted": true,
        "outputId": "11fa4382-6090-40b3-e72f-dfef6d5d1115"
      },
      "source": [
        "def grader_decoder():\n",
        "    '''\n",
        "        out_vocab_size: Unique words of the target language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    out_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=10\n",
        "    dec_units=16 \n",
        "    batch_size=32\n",
        "    \n",
        "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    states=[state_h,state_c]\n",
        "    decoder=Decoder(out_vocab_size, embedding_dim, dec_units,input_length )\n",
        "    output,_,_=decoder(target_sentences, states)\n",
        "    assert(output.shape==(batch_size,input_length,dec_units))\n",
        "    return True\n",
        "print(grader_decoder())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "True\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXrIj4scLOe_",
        "execution": {
          "iopub.status.busy": "2021-08-28T06:24:42.745648Z",
          "iopub.execute_input": "2021-08-28T06:24:42.746079Z",
          "iopub.status.idle": "2021-08-28T06:24:42.753695Z",
          "shell.execute_reply.started": "2021-08-28T06:24:42.746048Z",
          "shell.execute_reply": "2021-08-28T06:24:42.752865Z"
        },
        "trusted": true
      },
      "source": [
        "class Encoder_decoder(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,*params):\n",
        "        super().__init__()\n",
        "        #Create encoder object\n",
        "        self.encoder = Encoder(inp_vocab_size = params[0], \n",
        "                               embedding_size = params[2], \n",
        "                               lstm_size = params[3], input_length = params[4])\n",
        "        #Create decoder object\n",
        "        self.decoder = Decoder(out_vocab_size = params[1], \n",
        "                              embedding_size = params[2], \n",
        "                              lstm_size = params[3], input_length = params[5])\n",
        "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
        "        self.dense = Dense(params[1], activation='softmax')\n",
        "    \n",
        "    def call(self,params, training = True):\n",
        "        '''\n",
        "        A. Pass the input sequence to Encoder layer -- Return encoder_output,encoder_final_state_h,encoder_final_state_c\n",
        "        B. Pass the target sequence to Decoder layer with intial states as encoder_final_state_h,encoder_final_state_C\n",
        "        C. Pass the decoder_outputs into Dense layer \n",
        "        \n",
        "        Return decoder_outputs\n",
        "        '''\n",
        "        enc_inp, dec_inp = params[0], params[1]\n",
        "        initial_state = self.encoder.initialize_states(batch_size)\n",
        "        output_state, enc_h, enc_c = self.encoder(enc_inp, initial_state)\n",
        "        output, _, _ = self.decoder(dec_inp ,[enc_h, enc_c])\n",
        "        return self.dense(output)\n",
        "        \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T13:15:13.012250Z",
          "iopub.execute_input": "2021-08-28T13:15:13.012743Z",
          "iopub.status.idle": "2021-08-28T13:15:13.027062Z",
          "shell.execute_reply.started": "2021-08-28T13:15:13.012709Z",
          "shell.execute_reply": "2021-08-28T13:15:13.026175Z"
        },
        "trusted": true,
        "id": "wdk7W7s3NwEN"
      },
      "source": [
        "\n",
        "class Dataset:\n",
        "    def __init__(self, data, tknizer_ita, tknizer_eng, max_len):\n",
        "        self.encoder_inps = data['italian'].values\n",
        "        self.decoder_inps = data['english_inp'].values\n",
        "        self.decoder_outs = data['english_out'].values\n",
        "        self.tknizer_eng = tknizer_eng\n",
        "        self.tknizer_ita = tknizer_ita\n",
        "        self.max_len     = max_len\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
        "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.decoder_inps[i]])\n",
        "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.decoder_outs[i]])\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "    def __len__(self): # your model.fit_gen requires this function\n",
        "        return len(self.encoder_inps)\n",
        "\n",
        "    \n",
        "class Dataloder(tf.keras.utils.Sequence):    \n",
        "    def __init__(self, dataset, batch_size):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "\n",
        "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
        "#         print(batch[0].shape, batch[1].shape, batch[2].shape)\n",
        "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
        "        return tuple([[tf.convert_to_tensor(batch[0]), tf.convert_to_tensor(batch[1])], tf.convert_to_tensor(batch[2])])\n",
        "\n",
        "    def __len__(self):  # your model.fit_gen requires this function\n",
        "        return len(self.indexes) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.random.permutation(self.indexes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T06:24:58.444935Z",
          "iopub.execute_input": "2021-08-28T06:24:58.445257Z",
          "iopub.status.idle": "2021-08-28T06:24:58.456286Z",
          "shell.execute_reply.started": "2021-08-28T06:24:58.445226Z",
          "shell.execute_reply": "2021-08-28T06:24:58.455373Z"
        },
        "trusted": true,
        "id": "29EzPTpKNwEO"
      },
      "source": [
        "batch_size=128\n",
        "lstm_size=64\n",
        "max_len = 20\n",
        "embedding_dim = 100\n",
        "dense_units = 64\n",
        "\n",
        "train_dataset = Dataset(train, tknizer_ita, tknizer_eng, max_len)\n",
        "test_dataset  = Dataset(test, tknizer_ita, tknizer_eng, max_len)\n",
        "\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=batch_size)\n",
        "test_dataloader = Dataloder(test_dataset, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T06:25:00.423857Z",
          "iopub.execute_input": "2021-08-28T06:25:00.424165Z",
          "iopub.status.idle": "2021-08-28T08:01:56.675745Z",
          "shell.execute_reply.started": "2021-08-28T06:25:00.424136Z",
          "shell.execute_reply": "2021-08-28T08:01:56.674769Z"
        },
        "trusted": true,
        "id": "V_KKwoeMNwEO",
        "outputId": "515ba946-cdd7-4503-936d-3f3ec49af1df"
      },
      "source": [
        "model = Encoder_decoder(vocab_size_ita+1, vocab_size_eng+1, \n",
        "                        embedding_dim, lstm_size, max_len, dense_units)\n",
        "model.compile(optimizer = 'Adam', loss = 'sparse_categorical_crossentropy',metrics='acc')\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "callbacks = [ModelCheckpoint('encoder_decoder', save_best_only= True, verbose = 1),\n",
        "             TensorBoard(log_dir = log_dir, histogram_freq=1, write_graph=True),\n",
        "             EarlyStopping(patience = 5, verbose = 1, monitor='val_loss',mode = 'min'),\n",
        "             ReduceLROnPlateau(patience = 3,factor=0.6, monitor='val_loss',mode = 'min',verbose = 1)]\n",
        "\n",
        "model.fit(x = train_dataloader, \n",
        "          steps_per_epoch = train_dataloader.__len__(),\n",
        "          validation_data = test_dataloader,\n",
        "          validation_steps = test_dataloader.__len__(),\n",
        "          epochs = 30,\n",
        "          verbose = 1,\n",
        "          callbacks = callbacks)\n",
        "model.save_weights('/kaggle/working/model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/30\n2471/2471 [==============================] - 196s 78ms/step - loss: 2.4140 - acc: 0.7061 - val_loss: 1.1414 - val_acc: 0.8046\n\nEpoch 00001: val_loss improved from inf to 1.14136, saving model to encoder_decoder\nEpoch 2/30\n2471/2471 [==============================] - 189s 77ms/step - loss: 1.0539 - acc: 0.8175 - val_loss: 0.8513 - val_acc: 0.8462\n\nEpoch 00002: val_loss improved from 1.14136 to 0.85134, saving model to encoder_decoder\nEpoch 3/30\n2471/2471 [==============================] - 190s 77ms/step - loss: 0.7915 - acc: 0.8545 - val_loss: 0.6814 - val_acc: 0.8710\n\nEpoch 00003: val_loss improved from 0.85134 to 0.68142, saving model to encoder_decoder\nEpoch 4/30\n2471/2471 [==============================] - 189s 77ms/step - loss: 0.6227 - acc: 0.8791 - val_loss: 0.5646 - val_acc: 0.8896\n\nEpoch 00004: val_loss improved from 0.68142 to 0.56458, saving model to encoder_decoder\nEpoch 5/30\n2471/2471 [==============================] - 190s 77ms/step - loss: 0.5045 - acc: 0.8977 - val_loss: 0.4845 - val_acc: 0.9027\n\nEpoch 00005: val_loss improved from 0.56458 to 0.48447, saving model to encoder_decoder\nEpoch 6/30\n2471/2471 [==============================] - 190s 77ms/step - loss: 0.4213 - acc: 0.9119 - val_loss: 0.4284 - val_acc: 0.9123\n\nEpoch 00006: val_loss improved from 0.48447 to 0.42843, saving model to encoder_decoder\nEpoch 7/30\n2471/2471 [==============================] - 190s 77ms/step - loss: 0.3588 - acc: 0.9229 - val_loss: 0.3897 - val_acc: 0.9193\n\nEpoch 00007: val_loss improved from 0.42843 to 0.38970, saving model to encoder_decoder\nEpoch 8/30\n2471/2471 [==============================] - 190s 77ms/step - loss: 0.3134 - acc: 0.9311 - val_loss: 0.3600 - val_acc: 0.9244\n\nEpoch 00008: val_loss improved from 0.38970 to 0.35997, saving model to encoder_decoder\nEpoch 9/30\n2471/2471 [==============================] - 190s 77ms/step - loss: 0.2788 - acc: 0.9377 - val_loss: 0.3376 - val_acc: 0.9288\n\nEpoch 00009: val_loss improved from 0.35997 to 0.33764, saving model to encoder_decoder\nEpoch 10/30\n2471/2471 [==============================] - 189s 77ms/step - loss: 0.2518 - acc: 0.9430 - val_loss: 0.3208 - val_acc: 0.9320\n\nEpoch 00010: val_loss improved from 0.33764 to 0.32079, saving model to encoder_decoder\nEpoch 11/30\n2471/2471 [==============================] - 188s 76ms/step - loss: 0.2289 - acc: 0.9473 - val_loss: 0.3069 - val_acc: 0.9349\n\nEpoch 00011: val_loss improved from 0.32079 to 0.30693, saving model to encoder_decoder\nEpoch 12/30\n2471/2471 [==============================] - 190s 77ms/step - loss: 0.2106 - acc: 0.9510 - val_loss: 0.2974 - val_acc: 0.9369\n\nEpoch 00012: val_loss improved from 0.30693 to 0.29735, saving model to encoder_decoder\nEpoch 13/30\n2471/2471 [==============================] - 189s 76ms/step - loss: 0.1959 - acc: 0.9539 - val_loss: 0.2882 - val_acc: 0.9386\n\nEpoch 00013: val_loss improved from 0.29735 to 0.28824, saving model to encoder_decoder\nEpoch 14/30\n2471/2471 [==============================] - 194s 79ms/step - loss: 0.1819 - acc: 0.9568 - val_loss: 0.2822 - val_acc: 0.9401\n\nEpoch 00014: val_loss improved from 0.28824 to 0.28224, saving model to encoder_decoder\nEpoch 15/30\n2471/2471 [==============================] - 196s 79ms/step - loss: 0.1711 - acc: 0.9589 - val_loss: 0.2741 - val_acc: 0.9422\n\nEpoch 00015: val_loss improved from 0.28224 to 0.27411, saving model to encoder_decoder\nEpoch 16/30\n2471/2471 [==============================] - 196s 79ms/step - loss: 0.1619 - acc: 0.9610 - val_loss: 0.2717 - val_acc: 0.9429\n\nEpoch 00016: val_loss improved from 0.27411 to 0.27170, saving model to encoder_decoder\nEpoch 17/30\n2471/2471 [==============================] - 196s 79ms/step - loss: 0.1521 - acc: 0.9631 - val_loss: 0.2677 - val_acc: 0.9439\n\nEpoch 00017: val_loss improved from 0.27170 to 0.26773, saving model to encoder_decoder\nEpoch 18/30\n2471/2471 [==============================] - 196s 79ms/step - loss: 0.1453 - acc: 0.9645 - val_loss: 0.2655 - val_acc: 0.9446\n\nEpoch 00018: val_loss improved from 0.26773 to 0.26552, saving model to encoder_decoder\nEpoch 19/30\n2471/2471 [==============================] - 196s 79ms/step - loss: 0.1379 - acc: 0.9661 - val_loss: 0.2616 - val_acc: 0.9458\n\nEpoch 00019: val_loss improved from 0.26552 to 0.26156, saving model to encoder_decoder\nEpoch 20/30\n2471/2471 [==============================] - 196s 79ms/step - loss: 0.1312 - acc: 0.9677 - val_loss: 0.2596 - val_acc: 0.9466\n\nEpoch 00020: val_loss improved from 0.26156 to 0.25961, saving model to encoder_decoder\nEpoch 21/30\n2471/2471 [==============================] - 196s 79ms/step - loss: 0.1262 - acc: 0.9687 - val_loss: 0.2600 - val_acc: 0.9467\n\nEpoch 00021: val_loss did not improve from 0.25961\nEpoch 22/30\n2471/2471 [==============================] - 196s 79ms/step - loss: 0.1219 - acc: 0.9698 - val_loss: 0.2567 - val_acc: 0.9479\n\nEpoch 00022: val_loss improved from 0.25961 to 0.25668, saving model to encoder_decoder\nEpoch 23/30\n2471/2471 [==============================] - 196s 79ms/step - loss: 0.1154 - acc: 0.9712 - val_loss: 0.2557 - val_acc: 0.9481\n\nEpoch 00023: val_loss improved from 0.25668 to 0.25575, saving model to encoder_decoder\nEpoch 24/30\n2471/2471 [==============================] - 196s 79ms/step - loss: 0.1116 - acc: 0.9720 - val_loss: 0.2544 - val_acc: 0.9486\n\nEpoch 00024: val_loss improved from 0.25575 to 0.25437, saving model to encoder_decoder\nEpoch 25/30\n2471/2471 [==============================] - 196s 79ms/step - loss: 0.1088 - acc: 0.9726 - val_loss: 0.2545 - val_acc: 0.9490\n\nEpoch 00025: val_loss did not improve from 0.25437\nEpoch 26/30\n2471/2471 [==============================] - 196s 79ms/step - loss: 0.1046 - acc: 0.9735 - val_loss: 0.2542 - val_acc: 0.9492\n\nEpoch 00026: val_loss improved from 0.25437 to 0.25424, saving model to encoder_decoder\nEpoch 27/30\n2471/2471 [==============================] - 196s 79ms/step - loss: 0.1009 - acc: 0.9744 - val_loss: 0.2547 - val_acc: 0.9497\n\nEpoch 00027: val_loss did not improve from 0.25424\nEpoch 28/30\n2471/2471 [==============================] - 196s 79ms/step - loss: 0.0987 - acc: 0.9747 - val_loss: 0.2541 - val_acc: 0.9500\n\nEpoch 00028: val_loss improved from 0.25424 to 0.25412, saving model to encoder_decoder\nEpoch 29/30\n2471/2471 [==============================] - 196s 79ms/step - loss: 0.0951 - acc: 0.9757 - val_loss: 0.2544 - val_acc: 0.9503\n\nEpoch 00029: val_loss did not improve from 0.25412\nEpoch 30/30\n2471/2471 [==============================] - 196s 79ms/step - loss: 0.0933 - acc: 0.9760 - val_loss: 0.2549 - val_acc: 0.9505\n\nEpoch 00030: val_loss did not improve from 0.25412\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T08:01:56.677339Z",
          "iopub.execute_input": "2021-08-28T08:01:56.677720Z",
          "iopub.status.idle": "2021-08-28T08:01:56.684121Z",
          "shell.execute_reply.started": "2021-08-28T08:01:56.677656Z",
          "shell.execute_reply": "2021-08-28T08:01:56.683081Z"
        },
        "trusted": true,
        "id": "gKJpzKmyNwEO",
        "outputId": "426a1b3a-acf1-418e-9475-671bb34cc098"
      },
      "source": [
        "model.layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 32,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[<__main__.Encoder at 0x7f02785ebf90>,\n <__main__.Decoder at 0x7f027993ae50>,\n <tensorflow.python.keras.layers.core.Dense at 0x7f027994f910>]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T08:01:56.686319Z",
          "iopub.execute_input": "2021-08-28T08:01:56.686732Z",
          "iopub.status.idle": "2021-08-28T08:01:56.699666Z",
          "shell.execute_reply.started": "2021-08-28T08:01:56.686693Z",
          "shell.execute_reply": "2021-08-28T08:01:56.698634Z"
        },
        "trusted": true,
        "id": "Y3iPaS1YNwEP"
      },
      "source": [
        "def predict(input_sentence):\n",
        "    '''\n",
        "      A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "      B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "      C. Initialize index of <start> as input to decoder. and encoder final states as input_states to decoder\n",
        "      D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predicted_out,state_h,state_c=model.layers[1](dec_input,states)\n",
        "         pass the predicted_out to the dense layer\n",
        "         update the states=[state_h,state_c]\n",
        "         And get the index of the word with maximum probability of the dense layer output, \n",
        "         using the tokenizer(word index) get the word and then store it in a string.\n",
        "         Update the input_to_decoder with current predictions\n",
        "      F. Return the predicted sentence\n",
        "    '''\n",
        "    sentencce = '<start> '+input_sentence+' <end>'\n",
        "    sentencce = tknizer_ita.texts_to_sequences([sentencce])\n",
        "    sentencce = pad_sequences(sentencce, maxlen=max_len, \n",
        "                              padding='post', dtype = np.int32)\n",
        "    \n",
        "    input_embedding = model.layers[0].encoder_embedding(sentencce)\n",
        "    initial_state =  model.layers[0].initialize_states(1)\n",
        "    ecoder_output, encoder_h, encoder_c = model.layers[0].encoder_Lstm(input_embedding,initial_state)\n",
        "    predict = np.expand_dims([tknizer_eng.word_index['<start>']], 0)\n",
        "    decoder_h = encoder_h\n",
        "    decoder_c = encoder_c\n",
        "    prediction = []\n",
        "    for words in range(max_len):\n",
        "        predict, decoder_h,decoder_c = model.layers[1](predict, [decoder_h, decoder_c])\n",
        "        predict = model.layers[2](predict)\n",
        "        predict = np.reshape(np.argmax(predict), (1, 1))\n",
        "        prediction.append(predict)\n",
        "    return prediction\n",
        "\n",
        "def get_sentence(prediction):\n",
        "    output = []\n",
        "    for i in result:\n",
        "        word = tknizer_eng.index_word[i[0][0]]\n",
        "        if word == '<end>':\n",
        "            break\n",
        "        output.append(word)\n",
        "    return ' '.join(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T08:01:56.701643Z",
          "iopub.execute_input": "2021-08-28T08:01:56.702044Z",
          "iopub.status.idle": "2021-08-28T08:01:56.810283Z",
          "shell.execute_reply.started": "2021-08-28T08:01:56.702005Z",
          "shell.execute_reply": "2021-08-28T08:01:56.809325Z"
        },
        "trusted": true,
        "id": "yhkcDsRONwEP",
        "outputId": "8399ea54-f2be-4712-c09e-60e43a1984b4"
      },
      "source": [
        "sentence = \"non pensi che non abbia provato\t\"\n",
        "print('input : ', sentence)\n",
        "result = predict(sentence)\n",
        "output = get_sentence(result)\n",
        "print('predicted output : ',output)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "input :  non pensi che non abbia provato\t\npredicted output :  do not you think i have not forgotten\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T08:01:56.811633Z",
          "iopub.execute_input": "2021-08-28T08:01:56.812193Z",
          "iopub.status.idle": "2021-08-28T08:01:56.908374Z",
          "shell.execute_reply.started": "2021-08-28T08:01:56.812152Z",
          "shell.execute_reply": "2021-08-28T08:01:56.907412Z"
        },
        "trusted": true,
        "id": "Mo6IoawGNwEP",
        "outputId": "edb909c7-3455-4d35-e1c1-50b93ee6a68a"
      },
      "source": [
        "sentence = train['italian'].values[5]\n",
        "print('input : ', sentence)\n",
        "result = predict(sentence)\n",
        "output = get_sentence(result)\n",
        "print('predicted output : ',output)\n",
        "print('actual output :', train['english_out'].values[5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "input :  tom è preparato per qualsiasi cosa possa capitare\npredicted output :  tom is prepared for anything that can happen\nactual output : tom is prepared for whatever may happen <end>\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T08:02:57.698401Z",
          "iopub.execute_input": "2021-08-28T08:02:57.698748Z",
          "iopub.status.idle": "2021-08-28T08:04:24.928386Z",
          "shell.execute_reply.started": "2021-08-28T08:02:57.698716Z",
          "shell.execute_reply": "2021-08-28T08:04:24.927400Z"
        },
        "trusted": true,
        "id": "nE4JYq9BNwEP",
        "outputId": "a40cf2f7-38db-4f8e-b72d-4c2797985489"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from numpy.random import permutation\n",
        "\n",
        "score =0\n",
        "for i in permutation(1000):\n",
        "    sentence = test['italian'].values[i]\n",
        "    reference = test['english_out'].values[i]\n",
        "    result = predict(sentence)\n",
        "    output = get_sentence(result)\n",
        "    score+= sentence_bleu([reference.split()],output.split())\n",
        "print('Bleu Score : {}'.format(score/1000))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Bleu Score : 0.6640184782391946\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxWFDxZXLOfJ"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZhX3K9GLOfJ"
      },
      "source": [
        "## Task -2: Including Attention mechanisum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3d7GeBMGbsJ"
      },
      "source": [
        "1. Use the preprocessed data from Task-1\n",
        "\n",
        "2. You have to implement an Encoder and Decoder architecture with  \n",
        "attention as discussed in the reference notebook.\n",
        "\n",
        "    * Encoder   - with 1 layer LSTM <br>\n",
        "    * Decoder   - with 1 layer LSTM<br>\n",
        "    * attention -  (Please refer the <a href= 'https://drive.google.com/file/d/1z_bnc-3aubKawbR6q8wyI6Mh5ho2R1aZ/view?usp=sharing'>**reference notebook**</a> to know more about the attention mechanism.)\n",
        "3. In Global attention, we have 3 types of scoring functions(as discussed in the reference notebook).\n",
        " As a part of this assignment **you need to create 3 models for each scoring function**\n",
        "<img src='https://i.imgur.com/iD2jZo3.png'>\n",
        "\n",
        "    * In model 1 you need to implemnt \"dot\" score function\n",
        "    * In model 2 you need to implemnt \"general\" score function\n",
        "    * In model 3 you need to implemnt \"concat\" score function.<br>\n",
        "    \n",
        " **Please do add the markdown titles for each model so that we can have a better look at the code and verify.**\n",
        "4. It is mandatory to train the model with simple model.fit() only, Donot train the model with custom GradientTape()\n",
        "\n",
        "5. Using attention weights, you can plot the attention plots, \n",
        "please plot those for 2-3 examples. You can check about those in <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\">this</a>\n",
        "\n",
        "6. The attention layer has to be written by yourself only. \n",
        "The main objective of this assignment is to read and implement a paper on yourself so please do it yourself.  \n",
        "\n",
        "7. Please implement the class **onestepdecoder** as mentioned in the assignment instructions.\n",
        "\n",
        "8. You can use any tf.Keras highlevel API's to build and train the models. \n",
        " Check the reference notebook for better understanding.\n",
        "\n",
        "9. Use BLEU score as metric to evaluate your model. You can use any loss function you need.\n",
        "\n",
        "10. You have to use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
        "\n",
        "11. Resources:\n",
        "    a. Check the reference notebook\n",
        "    b. <a href=\"https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\">Resource 1</a>\n",
        "    c. <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention\">Resource 2</a>\n",
        "    d. <a href=\"https://stackoverflow.com/questions/44238154/what-is-the-difference-between-luong-attention-and-bahdanau-attention#:~:text=Luong%20attention%20used%20top%20hidden,hidden%20state%20at%20time%20t.\">Resource 3</a>\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU4KIsGxLOfK"
      },
      "source": [
        "### <font color='blue'>**Implement custom encoder decoder and attention layers**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMm3ADQDLOfK"
      },
      "source": [
        "<font color='blue'>**Encoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx_5NA24KzRp",
        "execution": {
          "iopub.status.busy": "2021-08-28T13:15:13.028446Z",
          "iopub.execute_input": "2021-08-28T13:15:13.028795Z",
          "iopub.status.idle": "2021-08-28T13:15:13.039898Z",
          "shell.execute_reply.started": "2021-08-28T13:15:13.028761Z",
          "shell.execute_reply": "2021-08-28T13:15:13.039077Z"
        },
        "trusted": true
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns output sequence\n",
        "    '''\n",
        "\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "        super().__init__()\n",
        "        self.inp_vocab_size = inp_vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.lstm_size = lstm_size\n",
        "        self.input_length =input_length\n",
        "        #Initialize Embedding layer\n",
        "        self.encoder_embedding = Embedding(input_dim = inp_vocab_size,\n",
        "                                           output_dim = embedding_size,\n",
        "                                           input_length= input_length)\n",
        "        #Intialize Encoder LSTM layer\n",
        "        self.encoder_Lstm = LSTM(lstm_size, return_sequences = True, return_state = True)\n",
        "\n",
        "    def call(self,input_sequence,states):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "          returns -- All encoder_outputs, last time steps hidden and cell state\n",
        "        '''\n",
        "        input_embedding = self.encoder_embedding(input_sequence)\n",
        "        encoder_output_state, encoder_h, encoder_c = self.encoder_Lstm(input_embedding, initial_state = states)\n",
        "        return encoder_output_state, encoder_h, encoder_c\n",
        "    \n",
        "    def initialize_states(self,batch_size):\n",
        "        '''\n",
        "          Given a batch size it will return intial hidden state and intial cell state.\n",
        "          If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
        "        '''\n",
        "        return [tf.zeros((batch_size, self.lstm_size)), tf.zeros((batch_size, self.lstm_size))]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ub9aN-hK244"
      },
      "source": [
        "<font color='cyan'>**Grader function - 1**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRoe65b9LB0D",
        "execution": {
          "iopub.status.busy": "2021-08-28T13:15:13.041247Z",
          "iopub.execute_input": "2021-08-28T13:15:13.041825Z",
          "iopub.status.idle": "2021-08-28T13:15:19.932041Z",
          "shell.execute_reply.started": "2021-08-28T13:15:13.041785Z",
          "shell.execute_reply": "2021-08-28T13:15:19.931119Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3422199e-95da-4464-f029-48fc86a39561"
      },
      "source": [
        "def grader_check_encoder():\n",
        "    \n",
        "    '''\n",
        "        vocab-size: Unique words of the input language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        lstm_size: Number of lstm units in encoder,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    \n",
        "    vocab_size=10\n",
        "    embedding_size=20\n",
        "    lstm_size=32\n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
        "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
        "    initial_state=encoder.initialize_states(batch_size)\n",
        "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
        "    \n",
        "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
        "    return True\n",
        "print(grader_check_encoder())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXn278lhLYRM"
      },
      "source": [
        "<font color='blue'>**Attention**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab5SNdPZLlur",
        "execution": {
          "iopub.status.busy": "2021-08-28T13:15:19.933386Z",
          "iopub.execute_input": "2021-08-28T13:15:19.933894Z",
          "iopub.status.idle": "2021-08-28T13:15:19.945786Z",
          "shell.execute_reply.started": "2021-08-28T13:15:19.933856Z",
          "shell.execute_reply": "2021-08-28T13:15:19.944930Z"
        },
        "trusted": true
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "class Attention(tf.keras.layers.Layer):\n",
        "    '''\n",
        "        Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
        "        '''\n",
        "    def __init__(self,scoring_function, att_units):\n",
        "        super(Attention, self).__init__()\n",
        "        self.scoring_function = scoring_function\n",
        "        # Please go through the reference notebook and research paper to complete the scoring functions\n",
        "\n",
        "        if self.scoring_function=='dot':\n",
        "            self.dot = Dot(axes = (1, 2))\n",
        "          # Intialize variables needed for Dot score function here\n",
        "            pass\n",
        "        if scoring_function == 'general':\n",
        "            self.D_0 = Dense(att_units)\n",
        "            self.dot = Dot(axes = (1, 2))\n",
        "            # Intialize variables needed for General score function here\n",
        "            pass\n",
        "        elif scoring_function == 'concat':\n",
        "            self.D_1 = Dense(att_units)\n",
        "            self.D_2 = Dense(att_units)\n",
        "            self.h = Dense(1)\n",
        "            # Intialize variables needed for Concat score function here\n",
        "            pass\n",
        "  \n",
        "    def call(self,decoder_hidden_state,encoder_output):\n",
        "        '''\n",
        "          Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
        "          * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
        "            Multiply the score function with your encoder_outputs to get the context vector.\n",
        "            Function returns context vector and attention weights(softmax - scores)\n",
        "        '''\n",
        "        decoder_hidden_state = tf.expand_dims(decoder_hidden_state, 1)\n",
        "        # Implement Dot score function here\n",
        "        if self.scoring_function == 'dot':\n",
        "            score = tf.transpose(self.dot([tf.transpose(decoder_hidden_state, (0, 2, 1)),\n",
        "                                       encoder_output]), (0, 2,1))\n",
        "            pass\n",
        "        elif self.scoring_function == 'general':\n",
        "            out = self.D_0(encoder_output)\n",
        "            score = tf.transpose(self.dot([tf.transpose(decoder_hidden_state, (0, 2, 1)), \n",
        "                                           out]), (0, 2,1))\n",
        "        # Implement General score function here\n",
        "            pass\n",
        "        elif self.scoring_function == 'concat':\n",
        "            stick = self.D_1(decoder_hidden_state) + self.D_2(encoder_output)\n",
        "            tan_h = tf.nn.tanh(stick)\n",
        "            score = self.h(tan_h)\n",
        "            # Implement General score function here\n",
        "            pass\n",
        "        attention_weights = tf.nn.softmax(score, axis =1)\n",
        "        context_vector = attention_weights * encoder_output\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        return context_vector, attention_weights\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExQDlxI9LuqK"
      },
      "source": [
        "<font color='cyan'>**Grader function - 2**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51x50h_TLrl9",
        "execution": {
          "iopub.status.busy": "2021-08-28T13:15:19.948529Z",
          "iopub.execute_input": "2021-08-28T13:15:19.948838Z",
          "iopub.status.idle": "2021-08-28T13:15:20.794689Z",
          "shell.execute_reply.started": "2021-08-28T13:15:19.948812Z",
          "shell.execute_reply": "2021-08-28T13:15:20.793760Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4d3a72d-163a-4f43-cec8-4a9d94febeab"
      },
      "source": [
        "def grader_check_attention(scoring_fun):\n",
        "    \n",
        "    ''' \n",
        "        att_units: Used in matrix multiplications for scoring functions,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    \n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    att_units=32\n",
        "    \n",
        "    state_h=tf.random.uniform(shape=[batch_size,att_units])\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,att_units])\n",
        "    attention=Attention(scoring_fun,att_units)\n",
        "    context_vector,attention_weights=attention(state_h,encoder_output)\n",
        "    assert(context_vector.shape==(batch_size,att_units) and attention_weights.shape==(batch_size,input_length,1))\n",
        "    return True\n",
        "print(grader_check_attention('dot'))\n",
        "print(grader_check_attention('general'))\n",
        "print(grader_check_attention('concat'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic-FNEbfL2DN"
      },
      "source": [
        "<font color='blue'>**OneStepDecoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc8m7lmOL097",
        "execution": {
          "iopub.status.busy": "2021-08-28T13:15:20.797036Z",
          "iopub.execute_input": "2021-08-28T13:15:20.797574Z",
          "iopub.status.idle": "2021-08-28T13:15:20.805999Z",
          "shell.execute_reply.started": "2021-08-28T13:15:20.797532Z",
          "shell.execute_reply": "2021-08-28T13:15:20.805126Z"
        },
        "trusted": true
      },
      "source": [
        "class OneStepDecoder(tf.keras.Model):\n",
        "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "    super().__init__()\n",
        "    # Initialize decoder embedding layer, LSTM and any other objects needed\n",
        "    self.decoder_embeddings = Embedding(input_dim = tar_vocab_size, output_dim = embedding_dim)\n",
        "    self.decoder_LSTM = LSTM(dec_units, return_sequences = True, return_state = True)\n",
        "    self.attention = Attention(scoring_function = score_fun, att_units = att_units)\n",
        "    self.feed_forward = Dense(tar_vocab_size)\n",
        "\n",
        "  def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
        "    '''\n",
        "        One step decoder mechanisim step by step:\n",
        "      A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
        "      B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
        "      C. Concat the context vector with the step A output\n",
        "      D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
        "      E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
        "      F. Return the states from step D, output from Step E, attention weights from Step -B\n",
        "    '''\n",
        "    decoder_embd = self.decoder_embeddings(input_to_decoder)\n",
        "    context_vector, attention_weights = self.attention(state_h, encoder_output)\n",
        "    concat_input = tf.concat([tf.expand_dims(context_vector, 1), decoder_embd], axis = -1)\n",
        "    decoder_output_states, decoder_h, decoder_c = self.decoder_LSTM(concat_input, [state_h, state_c])\n",
        "    output = tf.reshape(decoder_output_states, (-1, decoder_output_states.shape[2]))\n",
        "    output = self.feed_forward(output)\n",
        "    return output, decoder_h, decoder_c, attention_weights, context_vector\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_I8I4EIMAXq"
      },
      "source": [
        "<font color='cyan'>**Grader function - 3**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLEXhChnMC1k",
        "execution": {
          "iopub.status.busy": "2021-08-28T13:15:20.807556Z",
          "iopub.execute_input": "2021-08-28T13:15:20.808083Z",
          "iopub.status.idle": "2021-08-28T13:15:20.891400Z",
          "shell.execute_reply.started": "2021-08-28T13:15:20.808045Z",
          "shell.execute_reply": "2021-08-28T13:15:20.890072Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6e70b33-c7ff-4665-fee4-3c55d077ca58"
      },
      "source": [
        "def grader_onestepdecoder(score_fun):\n",
        "    \n",
        "    '''\n",
        "        tar_vocab_size: Unique words of the target language,\n",
        "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
        "        input_length: Length of the target sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    \n",
        "    tar_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=10\n",
        "    dec_units=16 \n",
        "    att_units=16\n",
        "    batch_size=32\n",
        "    onestepdecoder=OneStepDecoder(tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
        "    input_to_decoder=tf.random.uniform(shape=(batch_size,1),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    output,state_h,state_c,attention_weights,context_vector=onestepdecoder(input_to_decoder,encoder_output,state_h,state_c)\n",
        "    assert(output.shape==(batch_size,tar_vocab_size))\n",
        "    assert(state_h.shape==(batch_size,dec_units))\n",
        "    assert(state_c.shape==(batch_size,dec_units))\n",
        "    assert(attention_weights.shape==(batch_size,input_length,1))\n",
        "    assert(context_vector.shape==(batch_size,dec_units))\n",
        "    return True\n",
        "    \n",
        "print(grader_onestepdecoder('dot'))\n",
        "print(grader_onestepdecoder('general'))\n",
        "print(grader_onestepdecoder('concat'))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FHrurjUMGAi"
      },
      "source": [
        "<font color='blue'>**Decoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV-x31rj6Hc4",
        "execution": {
          "iopub.status.busy": "2021-08-28T13:15:20.892747Z",
          "iopub.execute_input": "2021-08-28T13:15:20.893068Z",
          "iopub.status.idle": "2021-08-28T13:15:20.902486Z",
          "shell.execute_reply.started": "2021-08-28T13:15:20.893034Z",
          "shell.execute_reply": "2021-08-28T13:15:20.901079Z"
        },
        "trusted": true
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "        super().__init__()\n",
        "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
        "        self.out_vocab_size = out_vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.input_length = input_length\n",
        "        self.dec_units = dec_units\n",
        "        self.score_fun = score_fun\n",
        "        self.att_units = att_units\n",
        "        self.one_step_decoder = OneStepDecoder(out_vocab_size, embedding_dim, input_length, \n",
        "                                               dec_units ,score_fun ,att_units)\n",
        "        \n",
        "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
        "\n",
        "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
        "        all_outputs = tf.TensorArray(dtype = tf.float32, \n",
        "                                     size= input_to_decoder.shape[1], name='output_arrays')\n",
        "        #Create a tensor array as shown in the reference notebook\n",
        "        for timestep in range(input_to_decoder.shape[1]):\n",
        "            output, decoder_hidden_state, decoder_cell_state, _, _ = self.one_step_decoder(\n",
        "                input_to_decoder[:, timestep:timestep+1], \n",
        "                encoder_output, decoder_hidden_state,decoder_cell_state)\n",
        "        #Iterate till the length of the decoder input\n",
        "            # Call onestepdecoder for each token in decoder_input\n",
        "            # Store the output in tensorarray\n",
        "            all_outputs = all_outputs.write(timestep, output)\n",
        "        # Return the tensor array\n",
        "        all_outputs = tf.transpose(all_outputs.stack(), (1, 0, 2))\n",
        "        return all_outputs\n",
        "        \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxrL-P8bMJH6"
      },
      "source": [
        "<font color='cyan'>**Grader function - 4**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtbx6onFMJXb",
        "execution": {
          "iopub.status.busy": "2021-08-28T13:15:20.904307Z",
          "iopub.execute_input": "2021-08-28T13:15:20.904722Z",
          "iopub.status.idle": "2021-08-28T13:15:21.141545Z",
          "shell.execute_reply.started": "2021-08-28T13:15:20.904688Z",
          "shell.execute_reply": "2021-08-28T13:15:21.140637Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "795f2731-ca1e-4199-ab75-0ccc3716f6c5"
      },
      "source": [
        "def grader_decoder(score_fun):\n",
        "    \n",
        "    '''\n",
        "        out_vocab_size: Unique words of the target language,\n",
        "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
        "        input_length: Length of the target sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    \n",
        "    out_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=11\n",
        "    dec_units=16 \n",
        "    att_units=16\n",
        "    batch_size=32\n",
        "    \n",
        "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    \n",
        "    decoder=Decoder(out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
        "    output=decoder(target_sentences,encoder_output, state_h, state_c)\n",
        "    assert(output.shape==(batch_size,input_length,out_vocab_size))\n",
        "    return True\n",
        "print(grader_decoder('dot'))\n",
        "print(grader_decoder('general'))\n",
        "print(grader_decoder('concat'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC1T1EOoMTqC"
      },
      "source": [
        "<font color='blue'>**Encoder Decoder model**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfqBIe20MT3D",
        "execution": {
          "iopub.status.busy": "2021-08-28T13:15:21.142861Z",
          "iopub.execute_input": "2021-08-28T13:15:21.143379Z",
          "iopub.status.idle": "2021-08-28T13:15:21.152682Z",
          "shell.execute_reply.started": "2021-08-28T13:15:21.143339Z",
          "shell.execute_reply": "2021-08-28T13:15:21.151766Z"
        },
        "trusted": true
      },
      "source": [
        "class encoder_decoder(tf.keras.Model):\n",
        "  def __init__(self, inp_vocab_size, out_vocab_size, embedding_dim, \n",
        "               enc_units, dec_units, max_len, score_fun, att_units, batch_size):\n",
        "    super().__init__()\n",
        "    #Intialize objects from encoder decoder\n",
        "    self.encoder = Encoder(inp_vocab_size, embedding_dim, enc_units, max_len)\n",
        "    self.one_step_decoder = OneStepDecoder(out_vocab_size, embedding_dim,\n",
        "                                           max_len, dec_units ,score_fun ,att_units)\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  @tf.function\n",
        "  def call(self,data):\n",
        "    #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
        "    encoder_inp, decoder_inp = data[0], data[1]\n",
        "    initial_state = self.encoder.initialize_states(self.batch_size)\n",
        "    encoder_output, encoder_h, encoder_c = self.encoder(encoder_inp, initial_state)\n",
        "    all_outputs = tf.TensorArray(dtype = tf.float32, size= max_len)\n",
        "    # Decoder initial states are encoder final states, Initialize it accordingly\n",
        "    decoder_h = encoder_h\n",
        "    decoder_c = encoder_c\n",
        "    # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
        "    for timestep in range(max_len):\n",
        "        decoder_output, decoder_h, decoder_c, _, _ = self.one_step_decoder(decoder_inp[:, timestep:timestep+1], \n",
        "                                                               encoder_output, \n",
        "                                                               decoder_h,\n",
        "                                                               decoder_c)\n",
        "        all_outputs = all_outputs.write(timestep, decoder_output)\n",
        "    all_outputs = tf.transpose(all_outputs.stack(), (1, 0, 2))\n",
        "    # return the decoder output\n",
        "    return all_outputs\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVRxB-FDMJWL"
      },
      "source": [
        "<font color='blue'>**Custom loss function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY_3izrXMs8y",
        "execution": {
          "iopub.status.busy": "2021-08-28T13:15:21.154002Z",
          "iopub.execute_input": "2021-08-28T13:15:21.154355Z",
          "iopub.status.idle": "2021-08-28T13:15:21.165873Z",
          "shell.execute_reply.started": "2021-08-28T13:15:21.154318Z",
          "shell.execute_reply": "2021-08-28T13:15:21.165143Z"
        },
        "trusted": true
      },
      "source": [
        "#https://www.tensorflow.org/tutorials/text/image_captioning#model\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    \"\"\" Custom loss function that will not consider the loss for padded zeros.\n",
        "    why are we using this, can't we use simple sparse categorical crossentropy?\n",
        "    Yes, you can use simple sparse categorical crossentropy as loss like we did in task-1. But in this loss function we are ignoring the loss\n",
        "    for the padded zeros. i.e when the input is zero then we donot need to worry what the output is. This padded zeros are added from our end\n",
        "    during preprocessing to make equal length for all the sentences.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvPvwogANwEV"
      },
      "source": [
        "# <font color='blue'>**1 . Model with Dot Scoring function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0caTcr0H0ITt"
      },
      "source": [
        "from tensorflow.keras.callbacks import*\n",
        "import os\n",
        "batch_size=128\n",
        "enc_unit=512\n",
        "dec_unit=512\n",
        "max_len = 20\n",
        "embedding_dim = 256\n",
        "att_units = 256\n",
        "\n",
        "train_dataset = Dataset(train, tknizer_ita, tknizer_eng, max_len)\n",
        "test_dataset  = Dataset(test, tknizer_ita, tknizer_eng, max_len)\n",
        "\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=batch_size)\n",
        "test_dataloader = Dataloder(test_dataset, batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T08:05:03.137428Z",
          "iopub.execute_input": "2021-08-28T08:05:03.137781Z",
          "iopub.status.idle": "2021-08-28T08:05:03.513469Z",
          "shell.execute_reply.started": "2021-08-28T08:05:03.137747Z",
          "shell.execute_reply": "2021-08-28T08:05:03.512569Z"
        },
        "trusted": true,
        "id": "vVcLkS6ZNwEV"
      },
      "source": [
        "Attention_dot_model = encoder_decoder(vocab_size_ita+1, vocab_size_eng+1, embedding_dim, enc_unit,\n",
        "                        dec_unit, max_len ,'dot', att_units, batch_size)\n",
        "Attention_dot_model.compile(optimizer = 'Adam', loss = loss_function)\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "callbacks = [ModelCheckpoint('/content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot', save_best_only= True, verbose = 1),\n",
        "             TensorBoard(log_dir = log_dir, histogram_freq=1, write_graph=True),\n",
        "             EarlyStopping(patience = 3, verbose = 1, monitor = 'val_loss', mode='min'),\n",
        "             ReduceLROnPlateau(patience = 1, verbose = 1, monior='val_loss', mode = 'min', factor = 0.6)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T08:05:04.369761Z",
          "iopub.execute_input": "2021-08-28T08:05:04.370097Z",
          "iopub.status.idle": "2021-08-28T09:28:21.488871Z",
          "shell.execute_reply.started": "2021-08-28T08:05:04.370065Z",
          "shell.execute_reply": "2021-08-28T09:28:21.487948Z"
        },
        "trusted": true,
        "id": "snC8qqDmNwEV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aea062d-bead-4ce1-bdf4-d7a4d0ef72bc"
      },
      "source": [
        "Attention_dot_model.fit(x = train_dataloader, \n",
        "          steps_per_epoch = train_dataloader.__len__(),\n",
        "          validation_data = test_dataloader,\n",
        "          validation_steps = test_dataloader.__len__(),\n",
        "          epochs = 10,\n",
        "          verbose = 1,\n",
        "          callbacks = callbacks)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2471/2471 [==============================] - 676s 266ms/step - loss: 1.1423 - val_loss: 0.6849\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.68489, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, dot_8_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10\n",
            "2471/2471 [==============================] - 651s 263ms/step - loss: 0.4629 - val_loss: 0.3264\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.68489 to 0.32640, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, dot_8_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10\n",
            "2471/2471 [==============================] - 651s 264ms/step - loss: 0.2326 - val_loss: 0.2236\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.32640 to 0.22356, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, dot_8_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10\n",
            "2471/2471 [==============================] - 651s 263ms/step - loss: 0.1472 - val_loss: 0.1859\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.22356 to 0.18594, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, dot_8_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10\n",
            "2471/2471 [==============================] - 651s 263ms/step - loss: 0.1053 - val_loss: 0.1677\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.18594 to 0.16772, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, dot_8_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10\n",
            "2471/2471 [==============================] - 651s 263ms/step - loss: 0.0804 - val_loss: 0.1570\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.16772 to 0.15700, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, dot_8_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10\n",
            "2471/2471 [==============================] - 651s 264ms/step - loss: 0.0645 - val_loss: 0.1518\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.15700 to 0.15183, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, dot_8_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10\n",
            "2471/2471 [==============================] - 652s 264ms/step - loss: 0.0535 - val_loss: 0.1502\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.15183 to 0.15019, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, dot_8_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10\n",
            "2471/2471 [==============================] - 652s 264ms/step - loss: 0.0460 - val_loss: 0.1488\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.15019 to 0.14883, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, dot_8_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/Attention_dot/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10\n",
            "2471/2471 [==============================] - 651s 263ms/step - loss: 0.0402 - val_loss: 0.1497\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.14883\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc8de602f10>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T09:28:26.254314Z",
          "iopub.execute_input": "2021-08-28T09:28:26.254652Z",
          "iopub.status.idle": "2021-08-28T09:28:26.262643Z",
          "shell.execute_reply.started": "2021-08-28T09:28:26.254620Z",
          "shell.execute_reply": "2021-08-28T09:28:26.261598Z"
        },
        "trusted": true,
        "id": "8a1e2uPuNwEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61a1bd81-2620-4004-b211-af1e72643cb2"
      },
      "source": [
        "Attention_dot_model.layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<__main__.Encoder at 0x7fc94e4557d0>,\n",
              " <__main__.OneStepDecoder at 0x7fc8de62a350>]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DpC9zlzMcXp"
      },
      "source": [
        "# <font color='blue'>**1.1 Inference Model-1**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5NhESYyMW_t"
      },
      "source": [
        "<font color='blue'>**Plot attention weights**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkEY7SsBMtrC",
        "execution": {
          "iopub.status.busy": "2021-08-28T13:39:00.248555Z",
          "iopub.execute_input": "2021-08-28T13:39:00.248885Z",
          "iopub.status.idle": "2021-08-28T13:39:00.256550Z",
          "shell.execute_reply.started": "2021-08-28T13:39:00.248857Z",
          "shell.execute_reply": "2021-08-28T13:39:00.255489Z"
        },
        "trusted": true
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "  #Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1IhdBrgQYJr"
      },
      "source": [
        "<font color='blue'>**Predict the sentence translation**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP3kLZoPMvSu",
        "execution": {
          "iopub.status.busy": "2021-08-28T09:28:30.275155Z",
          "iopub.execute_input": "2021-08-28T09:28:30.275486Z",
          "iopub.status.idle": "2021-08-28T09:28:30.287305Z",
          "shell.execute_reply.started": "2021-08-28T09:28:30.275455Z",
          "shell.execute_reply": "2021-08-28T09:28:30.286318Z"
        },
        "trusted": true
      },
      "source": [
        "def predict_model_1(input_sentence):\n",
        "    '''\n",
        "      A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "      B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "      C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "      D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "         Save the attention weights\n",
        "         And get the word using the tokenizer(word index) and then store it in a string.\n",
        "      E. Call plot_attention(#params)\n",
        "      F. Return the predicted sentence\n",
        "    '''\n",
        "    sentencce = '<start> '+input_sentence+' <end>'\n",
        "    sentencce = tknizer_ita.texts_to_sequences([sentencce])\n",
        "    sentencce = pad_sequences(sentencce, maxlen=max_len, \n",
        "                              padding='post', dtype = np.int32)\n",
        "    \n",
        "    input_embedding = Attention_dot_model.layers[0].encoder_embedding(sentencce)\n",
        "    initial_state =  Attention_dot_model.layers[0].initialize_states(1)\n",
        "    ecoder_output, encoder_h, encoder_c = Attention_dot_model.layers[0].encoder_Lstm(input_embedding,initial_state)\n",
        "    predict = np.expand_dims([tknizer_eng.word_index['<start>']], 0)\n",
        "    decoder_h = encoder_h\n",
        "    decoder_c = encoder_c\n",
        "    prediction = []\n",
        "    total_attention = []\n",
        "    for words in range(max_len):\n",
        "        predict, decoder_h,decoder_c,attention,_ = Attention_dot_model.layers[1](predict,ecoder_output,\n",
        "                                                                                             decoder_h,decoder_c,training = False)\n",
        "        predict = np.reshape(np.argmax(predict), (1, 1))                                                                                      \n",
        "        prediction.append(predict)\n",
        "        total_attention.append(attention)\n",
        "    return prediction, total_attention\n",
        "\n",
        "def get_sentence(prediction):\n",
        "    output = []\n",
        "    for i in prediction:\n",
        "        word = tknizer_eng.index_word[i[0][0]]\n",
        "        if word == '<end>':\n",
        "            break\n",
        "        output.append(word)\n",
        "    return ' '.join(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T09:28:31.255327Z",
          "iopub.execute_input": "2021-08-28T09:28:31.255706Z",
          "iopub.status.idle": "2021-08-28T09:28:31.380722Z",
          "shell.execute_reply.started": "2021-08-28T09:28:31.255655Z",
          "shell.execute_reply": "2021-08-28T09:28:31.379734Z"
        },
        "trusted": true,
        "id": "9dLZdR4uNwEX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd1029e-4aa4-4e64-b727-602ed338dd1a"
      },
      "source": [
        "sentence = \"non mi trattate come una bambina\"\n",
        "print('input : ', sentence)\n",
        "result,weights = predict(sentence)\n",
        "output = get_sentence(result)\n",
        "print('predicted output : ',output)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input :  non mi trattate come una bambina\n",
            "predicted output :  do not treat me like a child\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T09:28:33.698572Z",
          "iopub.execute_input": "2021-08-28T09:28:33.698980Z",
          "iopub.status.idle": "2021-08-28T09:28:34.165579Z",
          "shell.execute_reply.started": "2021-08-28T09:28:33.698933Z",
          "shell.execute_reply": "2021-08-28T09:28:34.164506Z"
        },
        "trusted": true,
        "id": "hhr_e3aYNwEX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "3f362680-c7e8-4dc4-878f-eafc2c4ed067"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "sentence = test['italian'].values[5]\n",
        "print('input : ', sentence)\n",
        "result, attention_plot = predict(sentence)\n",
        "output = get_sentence(result)\n",
        "attention_plot = np.squeeze(np.squeeze(np.array(attention_plot), 1), -1)\n",
        "attention_plot = attention_plot[:len(output.split(' ')), :len(sentence.split(' '))]\n",
        "plot_attention(attention_plot, sentence.split(' '), output.split(' '))\n",
        "print('predicted output : ',output)\n",
        "print('actual output :', test['english_out'].values[5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input :  non mi trattate come una bambina\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted output :  do not treat me like a child\n",
            "actual output : do not treat me like a child <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmxIVOOQPWMu"
      },
      "source": [
        "<font color='blue'>**Calculate BLEU score**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iHiLdROM23l",
        "execution": {
          "iopub.status.busy": "2021-08-28T09:28:56.384961Z",
          "iopub.execute_input": "2021-08-28T09:28:56.385285Z",
          "iopub.status.idle": "2021-08-28T09:30:50.708229Z",
          "shell.execute_reply.started": "2021-08-28T09:28:56.385256Z",
          "shell.execute_reply": "2021-08-28T09:30:50.707279Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "898168a9-3ac6-4516-b32e-25444ffba1db"
      },
      "source": [
        "#Create an object of your custom model.\n",
        "#Compile and train your model on dot scoring function.\n",
        "# Visualize few sentences randomly in Test data\n",
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "\n",
        "#Sample example\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from numpy.random import permutation\n",
        "score =0\n",
        "res = []\n",
        "for i in permutation(1000):\n",
        "    sentence = test['italian'].values[i]\n",
        "    reference = test['english_out'].values[i][:-5]\n",
        "    values, weights = predict_model_1(sentence)\n",
        "    get_answer = get_sentence(values)\n",
        "    #print(get_answer)\n",
        "    score+= sentence_bleu([reference.split()], get_answer.split())\n",
        "print('Bleu Score : {}'.format(score/1000))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bleu Score : 0.8625677426893841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWg2ferDQvT3"
      },
      "source": [
        "# <font color='blue'>**2. Model for General scoring function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T13:15:26.283978Z",
          "iopub.execute_input": "2021-08-28T13:15:26.284329Z",
          "iopub.status.idle": "2021-08-28T13:15:26.291316Z",
          "shell.execute_reply.started": "2021-08-28T13:15:26.284298Z",
          "shell.execute_reply": "2021-08-28T13:15:26.290243Z"
        },
        "trusted": true,
        "id": "dfRIEWW9NwEY"
      },
      "source": [
        "from tensorflow.keras.callbacks import*\n",
        "import os\n",
        "batch_size=256\n",
        "enc_unit=256\n",
        "dec_unit=256\n",
        "max_len = 20\n",
        "embedding_dim = 100\n",
        "att_units = 256\n",
        "\n",
        "train_dataset = Dataset(train, tknizer_ita, tknizer_eng, max_len)\n",
        "test_dataset  = Dataset(test, tknizer_ita, tknizer_eng, max_len)\n",
        "\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=batch_size)\n",
        "test_dataloader = Dataloder(test_dataset, batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T13:15:36.328704Z",
          "iopub.execute_input": "2021-08-28T13:15:36.329023Z",
          "iopub.status.idle": "2021-08-28T13:15:36.851294Z",
          "shell.execute_reply.started": "2021-08-28T13:15:36.328993Z",
          "shell.execute_reply": "2021-08-28T13:15:36.850328Z"
        },
        "trusted": true,
        "id": "1GgbzdSzNwEY"
      },
      "source": [
        "General_scr_model = encoder_decoder(vocab_size_ita+1, vocab_size_eng+1, embedding_dim, enc_unit,\n",
        "                        dec_unit, max_len ,'general', att_units, batch_size)\n",
        "General_scr_model.compile(optimizer = 'Adam', loss = loss_function)\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "callbacks = [ModelCheckpoint('/content/drive/MyDrive/Seq_Seq_attention/Save/General', save_best_only= True, verbose = 1),\n",
        "             #TensorBoard(log_dir = log_dir, histogram_freq=1, write_graph=True),\n",
        "             EarlyStopping(patience = 5, verbose = 1, monitor = 'val_loss', mode='min'),\n",
        "             ReduceLROnPlateau(patience = 1, verbose = 1, monior='val_loss', mode = 'min', factor = 0.6)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T13:15:38.598844Z",
          "iopub.execute_input": "2021-08-28T13:15:38.599215Z",
          "iopub.status.idle": "2021-08-28T13:37:54.779450Z",
          "shell.execute_reply.started": "2021-08-28T13:15:38.599178Z",
          "shell.execute_reply": "2021-08-28T13:37:54.778559Z"
        },
        "trusted": true,
        "id": "3DlSQywGNwEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "558c78a5-f60d-43f2-8d5e-b3f979528766"
      },
      "source": [
        "General_scr_model.fit(x = train_dataloader, \n",
        "          steps_per_epoch = train_dataloader.__len__(),\n",
        "          validation_data = test_dataloader,\n",
        "          validation_steps = test_dataloader.__len__(),\n",
        "          epochs = 10,\n",
        "          verbose = 1,\n",
        "          callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1235/1235 [==============================] - 139s 101ms/step - loss: 1.4756 - val_loss: 1.0753\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.07526, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/General\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, dense_18_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/General/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/General/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10\n",
            "1235/1235 [==============================] - 122s 99ms/step - loss: 0.8736 - val_loss: 0.7072\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.07526 to 0.70723, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/General\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, dense_18_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/General/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/General/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10\n",
            "1235/1235 [==============================] - 122s 99ms/step - loss: 0.5722 - val_loss: 0.4813\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.70723 to 0.48135, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/General\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, dense_18_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/General/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/General/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10\n",
            "1235/1235 [==============================] - 127s 103ms/step - loss: 0.3816 - val_loss: 0.3502\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.48135 to 0.35015, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/General\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, dense_18_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/General/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/General/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10\n",
            "1235/1235 [==============================] - 122s 99ms/step - loss: 0.2670 - val_loss: 0.2753\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.35015 to 0.27533, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/General\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, dense_18_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/General/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/General/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10\n",
            "1235/1235 [==============================] - 123s 99ms/step - loss: 0.1986 - val_loss: 0.2335\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.27533 to 0.23349, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/General\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, dense_18_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/General/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/General/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10\n",
            "1235/1235 [==============================] - 123s 99ms/step - loss: 0.1548 - val_loss: 0.2082\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.23349 to 0.20820, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/General\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, dense_18_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/General/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/General/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10\n",
            "1235/1235 [==============================] - 122s 99ms/step - loss: 0.1251 - val_loss: 0.1909\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.20820 to 0.19090, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/General\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, dense_18_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/General/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/General/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10\n",
            "1235/1235 [==============================] - 123s 99ms/step - loss: 0.1039 - val_loss: 0.1778\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.19090 to 0.17779, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/General\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, dense_18_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/General/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/General/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10\n",
            "1235/1235 [==============================] - 123s 99ms/step - loss: 0.0881 - val_loss: 0.1722\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.17779 to 0.17222, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/General\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, dense_18_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/General/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/General/assets\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5b0545c9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRX_9XolNwEY"
      },
      "source": [
        "## <font color='blue'>**2.1 Inference Model-2**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T13:39:07.935657Z",
          "iopub.execute_input": "2021-08-28T13:39:07.935986Z",
          "iopub.status.idle": "2021-08-28T13:39:08.416456Z",
          "shell.execute_reply.started": "2021-08-28T13:39:07.935956Z",
          "shell.execute_reply": "2021-08-28T13:39:08.415572Z"
        },
        "trusted": true,
        "id": "d3tqaisRNwEZ"
      },
      "source": [
        "from tensorflow.keras.callbacks import*\n",
        "import os\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from numpy.random import permutation\n",
        "\n",
        "def predict_model_2(input_sentence):\n",
        "    '''\n",
        "      A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "      B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "      C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "      D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "         Save the attention weights\n",
        "         And get the word using the tokenizer(word index) and then store it in a string.\n",
        "      E. Call plot_attention(#params)\n",
        "      F. Return the predicted sentence\n",
        "    '''\n",
        "    sentencce = '<start> '+input_sentence+' <end>'\n",
        "    sentencce = tknizer_ita.texts_to_sequences([sentencce])\n",
        "    sentencce = pad_sequences(sentencce, maxlen=max_len, \n",
        "                              padding='post', dtype = np.int32)\n",
        "    \n",
        "    input_embedding = General_scr_model.layers[0].encoder_embedding(sentencce)\n",
        "    initial_state =  General_scr_model.layers[0].initialize_states(1)\n",
        "    ecoder_output, encoder_h, encoder_c = General_scr_model.layers[0].encoder_Lstm(input_embedding,initial_state)\n",
        "    predict = np.expand_dims([tknizer_eng.word_index['<start>']], 0)\n",
        "    decoder_h = encoder_h\n",
        "    decoder_c = encoder_c\n",
        "    prediction = []\n",
        "    total_attention = []\n",
        "    for words in range(max_len):\n",
        "        predict, decoder_h,decoder_c,attention,_ = General_scr_model.layers[1](predict,ecoder_output,\n",
        "                                                                                             decoder_h,decoder_c,training = False)\n",
        "        predict = np.reshape(np.argmax(predict), (1, 1))                                                                                      \n",
        "        prediction.append(predict)\n",
        "        total_attention.append(attention)\n",
        "    return prediction, total_attention\n",
        "\n",
        "def get_sentence(prediction):\n",
        "    output = []\n",
        "    for i in prediction:\n",
        "        word = tknizer_eng.index_word[i[0][0]]\n",
        "        if word == '<end>':\n",
        "            break\n",
        "        output.append(word)\n",
        "    return ' '.join(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T13:39:51.713828Z",
          "iopub.execute_input": "2021-08-28T13:39:51.714151Z",
          "iopub.status.idle": "2021-08-28T13:39:52.106982Z",
          "shell.execute_reply.started": "2021-08-28T13:39:51.714121Z",
          "shell.execute_reply": "2021-08-28T13:39:52.105989Z"
        },
        "trusted": true,
        "id": "7yTyGy9FNwEZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "outputId": "4818ea26-14ff-4fbb-fe4d-8ebb46638201"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "sentence = train['italian'].values[57]\n",
        "print('input : ', sentence)\n",
        "result, attention_plot = predict_model_2(sentence)\n",
        "output = get_sentence(result)\n",
        "attention_plot = np.squeeze(np.squeeze(np.array(attention_plot), 1), -1)\n",
        "attention_plot = attention_plot[:len(output.split(' ')), :len(sentence.split(' '))]\n",
        "plot_attention(attention_plot, sentence.split(' '), output.split(' '))\n",
        "print('predicted output : ',output)\n",
        "print('actual output :', train['english_out'].values[57])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input :  dove sta andando tom con mary\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted output :  where is tom going with mary\n",
            "actual output : where is tom going with mary <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Rh9_w79M5JO",
        "execution": {
          "iopub.status.busy": "2021-08-28T13:40:04.513979Z",
          "iopub.execute_input": "2021-08-28T13:40:04.514337Z",
          "iopub.status.idle": "2021-08-28T13:41:59.767143Z",
          "shell.execute_reply.started": "2021-08-28T13:40:04.514305Z",
          "shell.execute_reply": "2021-08-28T13:41:59.766256Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a23f417f-8c41-420c-b2e3-4ea1d62c55db"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from numpy.random import permutation\n",
        "score =0\n",
        "for i in permutation(1000):\n",
        "    sentence = test['italian'].values[i]\n",
        "    reference = test['english_out'].values[i][:-5]\n",
        "    values, weights = predict_model_2(sentence)\n",
        "    prediction = get_sentence(values)\n",
        "    score+= sentence_bleu([reference.split()], prediction.split())\n",
        "print('Bleu Score : {}'.format(score/1000))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bleu Score : 0.830625967087493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VB1jRUqZQ9AM"
      },
      "source": [
        "# <font color='blue'>**3. Model for Concat scoring function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twe9UfO8IJDf"
      },
      "source": [
        "from tensorflow.keras.callbacks import*\n",
        "import os\n",
        "batch_size=256\n",
        "enc_unit=128\n",
        "dec_unit=128\n",
        "max_len = 20\n",
        "embedding_dim = 64\n",
        "att_units = 128\n",
        "\n",
        "train_dataset = Dataset(train, tknizer_ita, tknizer_eng, max_len)\n",
        "test_dataset  = Dataset(test, tknizer_ita, tknizer_eng, max_len)\n",
        "\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=batch_size)\n",
        "test_dataloader = Dataloder(test_dataset, batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T13:42:10.783327Z",
          "iopub.execute_input": "2021-08-28T13:42:10.783647Z",
          "iopub.status.idle": "2021-08-28T13:42:11.139204Z",
          "shell.execute_reply.started": "2021-08-28T13:42:10.783619Z",
          "shell.execute_reply": "2021-08-28T13:42:11.138295Z"
        },
        "trusted": true,
        "id": "XGEG6I6TNwEa"
      },
      "source": [
        "concat_score_model = encoder_decoder(vocab_size_ita+1, vocab_size_eng+1, embedding_dim, enc_unit,\n",
        "                        dec_unit, max_len ,'concat', att_units, batch_size)\n",
        "concat_score_model.compile(optimizer = 'Adam', loss = loss_function)\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "callbacks = [ModelCheckpoint('/content/drive/MyDrive/Seq_Seq_attention/Save/concat_score', save_best_only= True, verbose = 1),\n",
        "             TensorBoard(log_dir = log_dir, histogram_freq=1, write_graph=True),\n",
        "             EarlyStopping(patience = 5, verbose = 1, monitor = 'val_loss', mode='min'),\n",
        "             ReduceLROnPlateau(patience = 1, verbose = 1, monior='val_loss', mode = 'min', factor = 0.6)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T13:42:17.254450Z",
          "iopub.execute_input": "2021-08-28T13:42:17.254954Z",
          "iopub.status.idle": "2021-08-28T14:38:00.481997Z",
          "shell.execute_reply.started": "2021-08-28T13:42:17.254905Z",
          "shell.execute_reply": "2021-08-28T14:38:00.481109Z"
        },
        "trusted": true,
        "id": "KRiS-1GzNwEa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "101d05f8-aade-4133-ccbf-3ab1bd72355b"
      },
      "source": [
        "concat_score_model.fit(x = train_dataloader, \n",
        "          steps_per_epoch = train_dataloader.__len__(),\n",
        "          validation_data = test_dataloader,\n",
        "          validation_steps = test_dataloader.__len__(),\n",
        "          epochs = 15,\n",
        "          verbose = 1,\n",
        "          callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1235/1235 [==============================] - 145s 104ms/step - loss: 1.5655 - val_loss: 1.2091\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.20913, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn, dense_20_layer_call_and_return_conditional_losses while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/15\n",
            "1235/1235 [==============================] - 123s 100ms/step - loss: 1.0228 - val_loss: 0.8722\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.20913 to 0.87223, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn, dense_20_layer_call_and_return_conditional_losses while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/15\n",
            "1235/1235 [==============================] - 123s 100ms/step - loss: 0.7412 - val_loss: 0.6340\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.87223 to 0.63404, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn, dense_20_layer_call_and_return_conditional_losses while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/15\n",
            "1235/1235 [==============================] - 124s 100ms/step - loss: 0.5232 - val_loss: 0.4635\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.63404 to 0.46350, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn, dense_20_layer_call_and_return_conditional_losses while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/15\n",
            "1235/1235 [==============================] - 123s 100ms/step - loss: 0.3804 - val_loss: 0.3673\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.46350 to 0.36728, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn, dense_20_layer_call_and_return_conditional_losses while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/15\n",
            "1235/1235 [==============================] - 123s 100ms/step - loss: 0.2932 - val_loss: 0.3071\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.36728 to 0.30711, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn, dense_20_layer_call_and_return_conditional_losses while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/15\n",
            "1235/1235 [==============================] - 123s 100ms/step - loss: 0.2371 - val_loss: 0.2689\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.30711 to 0.26890, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn, dense_20_layer_call_and_return_conditional_losses while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/15\n",
            "1235/1235 [==============================] - 123s 100ms/step - loss: 0.1983 - val_loss: 0.2452\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.26890 to 0.24518, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn, dense_20_layer_call_and_return_conditional_losses while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/15\n",
            "1235/1235 [==============================] - 123s 100ms/step - loss: 0.1706 - val_loss: 0.2272\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.24518 to 0.22718, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn, dense_20_layer_call_and_return_conditional_losses while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/15\n",
            "1235/1235 [==============================] - 124s 100ms/step - loss: 0.1496 - val_loss: 0.2135\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.22718 to 0.21350, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn, dense_20_layer_call_and_return_conditional_losses while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/15\n",
            "1235/1235 [==============================] - 124s 100ms/step - loss: 0.1330 - val_loss: 0.2051\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.21350 to 0.20510, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn, dense_20_layer_call_and_return_conditional_losses while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/15\n",
            "1235/1235 [==============================] - 124s 100ms/step - loss: 0.1196 - val_loss: 0.1957\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.20510 to 0.19571, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn, dense_20_layer_call_and_return_conditional_losses while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/15\n",
            "1235/1235 [==============================] - 123s 100ms/step - loss: 0.1089 - val_loss: 0.1902\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.19571 to 0.19024, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn, dense_20_layer_call_and_return_conditional_losses while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/15\n",
            "1235/1235 [==============================] - 124s 100ms/step - loss: 0.0998 - val_loss: 0.1871\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.19024 to 0.18705, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn, dense_20_layer_call_and_return_conditional_losses while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/15\n",
            "1235/1235 [==============================] - 124s 100ms/step - loss: 0.0922 - val_loss: 0.1826\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.18705 to 0.18262, saving model to /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn, dense_20_layer_call_and_return_conditional_losses while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Seq_Seq_attention/Save/concat_score/assets\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f59de768250>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rgf95QZ2NwEa"
      },
      "source": [
        "## <font color='blue'>**3.1 Inference Model-3**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kN9ZWViQNMB",
        "execution": {
          "iopub.status.busy": "2021-08-28T14:38:25.045936Z",
          "iopub.execute_input": "2021-08-28T14:38:25.046271Z",
          "iopub.status.idle": "2021-08-28T14:38:25.057067Z",
          "shell.execute_reply.started": "2021-08-28T14:38:25.046242Z",
          "shell.execute_reply": "2021-08-28T14:38:25.056007Z"
        },
        "trusted": true
      },
      "source": [
        "def predict(input_sentence):\n",
        "    '''\n",
        "      A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "      B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "      C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "      D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "         Save the attention weights\n",
        "         And get the word using the tokenizer(word index) and then store it in a string.\n",
        "      E. Call plot_attention(#params)\n",
        "      F. Return the predicted sentence\n",
        "    '''\n",
        "    sentencce = '<start> '+input_sentence+' <end>'\n",
        "    sentencce = tknizer_ita.texts_to_sequences([sentencce])\n",
        "    sentencce = pad_sequences(sentencce, maxlen=max_len, \n",
        "                              padding='post', dtype = np.int32)\n",
        "    \n",
        "    input_embedding = concat_score_model.layers[0].encoder_embedding(sentencce)\n",
        "    initial_state =  concat_score_model.layers[0].initialize_states(1)\n",
        "    ecoder_output, encoder_h, encoder_c = concat_score_model.layers[0].encoder_Lstm(input_embedding,initial_state)\n",
        "    predict = np.expand_dims([tknizer_eng.word_index['<start>']], 0)\n",
        "    decoder_h = encoder_h\n",
        "    decoder_c = encoder_c\n",
        "    prediction = []\n",
        "    total_attention = []\n",
        "    for words in range(max_len):\n",
        "        predict, decoder_h,decoder_c,attention,_ = concat_score_model.layers[1](predict,ecoder_output,\n",
        "                                                                                             decoder_h,decoder_c,training = False)\n",
        "        predict = np.reshape(np.argmax(predict), (1, 1))                                                                                      \n",
        "        prediction.append(predict)\n",
        "        total_attention.append(attention)\n",
        "    return prediction, total_attention\n",
        "\n",
        "def get_sentence(prediction):\n",
        "    output = []\n",
        "    for i in prediction:\n",
        "        word = tknizer_eng.index_word[i[0][0]]\n",
        "        if word == '<end>':\n",
        "            break\n",
        "        output.append(word)\n",
        "    return ' '.join(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff1lV0ITM6_p",
        "execution": {
          "iopub.status.busy": "2021-08-28T14:38:52.503641Z",
          "iopub.execute_input": "2021-08-28T14:38:52.503978Z",
          "iopub.status.idle": "2021-08-28T14:38:52.864378Z",
          "shell.execute_reply.started": "2021-08-28T14:38:52.503948Z",
          "shell.execute_reply": "2021-08-28T14:38:52.863511Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "outputId": "1ae6388e-60c6-446f-df85-9af5ce9239ee"
      },
      "source": [
        "sentence = train['italian'].values[1248]\n",
        "print('input : ', sentence)\n",
        "result, attention_plot = predict(sentence)\n",
        "output = get_sentence(result)\n",
        "attention_plot = np.squeeze(np.squeeze(np.array(attention_plot), 1), -1)\n",
        "attention_plot = attention_plot[:len(output.split(' ')), :len(sentence.split(' '))]\n",
        "plot_attention(attention_plot, sentence.split(' '), output.split(' '))\n",
        "print('predicted output : ',output)\n",
        "print('actual output :', train['english_out'].values[1248])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input :  pensavo che potessimo parlare di tom\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted output :  i thought we could talk about tom\n",
            "actual output : i thought we could talk about tom <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-28T14:39:10.108611Z",
          "iopub.execute_input": "2021-08-28T14:39:10.108948Z",
          "iopub.status.idle": "2021-08-28T14:41:23.467045Z",
          "shell.execute_reply.started": "2021-08-28T14:39:10.108917Z",
          "shell.execute_reply": "2021-08-28T14:41:23.465427Z"
        },
        "trusted": true,
        "id": "acIoykEyNwEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0bdc984-b836-44de-c583-b27bf6b8e626"
      },
      "source": [
        "score =0\n",
        "for i in permutation(1000):\n",
        "    sentence = test['italian'].values[i]\n",
        "    reference = test['english_out'].values[i]\n",
        "    values, weights = predict(sentence)\n",
        "    prediction = get_sentence(values)\n",
        "    score+= sentence_bleu([reference.split()], prediction.split())\n",
        "print('Bleu Score : {}'.format(score/1000))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bleu Score : 0.68448575968482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d267arWup-Ce"
      },
      "source": [
        "# <font color='blue'>**Observation**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "692BaaxwqEoE"
      },
      "source": [
        "**Bascically What we want is to compute the context vector. The context vector is a vector with the same length as the input or source sequence and is computed at every time step of the decoder. Each of its values is the score (or the probability) of the corresponding word within the source sequence; they tell the decoder what to focus on at each time step. There are three ways to calculate the scores functions which is used in three different models.**\n",
        "________________________________________________________________________________\n",
        "**MODEL-1:**\n",
        "The hyperparameters are selected by various experiments. The best average BLEU score i got is 86%. \n",
        "\n",
        "What is happenning in Model-1?\n",
        "\n",
        "I order to compute the similarity between encoder outputs and decoder hidden state. Simiply taking the dot product between the two of them which represents the similarity between them. Using this similarity score now calucation the attention weights by passing this sccore into a softmax function. In order to get the context vector we multipied the attention weight with the encoder output.\n",
        "\n",
        "As the result in the attention weights which are plotted we can definately see that the word dependencies. Which word are has attention in order to traslate them.\n",
        "________________________________________________________________________________\n",
        "**MODEL-2**:\n",
        "The BLEU Score obtained is 83%. \n",
        "What is happenning in Model-2?\n",
        "\n",
        "Here the scoring function or similarity between decoder hidden state and ecoder outputs are defined as:\n",
        "\n",
        "Passing the encoder_outputs into a dense layer, Then doing a dot product between the output from the dense layer and decoder_hidden_state.\n",
        "\n",
        "By passing the ecoder_outputs to dense layer gives as weights which will be learned in order to get dependencies of words.\n",
        "________________________________________________________________________________\n",
        "**Model-3**:\n",
        "The BLEU score is somewhat 68%. I personally think this can be imporved by selecting diffrent hyperparametrs. Sicne i choose the hyperparameter exprementinally.\n",
        "\n",
        "In this Model the scoring function or the similarity is calucated as:\n",
        "The decoder hidden state and encoder hidden states are added together first before being passed through a linear layer with a tanh activation function and, finally, being multiplied by a weight matrix.\n",
        "In the aatention plot we can oberve that the word parlare means talk and in order to translate that particular word the attention weights are higher for talk compared to the neighouber words\n",
        "________________________________________________________________________________\n",
        "Since the sequnce length is fixed we cannot observe the effect of sequence length. But the all 3 attention has a drawback that it has to\n",
        "attend to all words on the source side for each target word, which is computaionally expensive and can potentially hard to translate longer sequences.\n",
        "To solve this problem we have Local Attention as mention in paper \n",
        "\"Effective Approaches to Attention-based Neural Machine Translation\""
      ]
    }
  ]
}