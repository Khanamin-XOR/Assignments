{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3sNKZq4XrXQh"
   },
   "source": [
    "# <font color='red'><b>Bootstrap assignment</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAHap1Z3FZC-"
   },
   "source": [
    "<b>There will be some functions that start with the word \"grader\" ex: grader_sampples(), grader_30().. etc, you should not change those function definition.\n",
    "\n",
    "Every Grader function has to return True.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cuxBq_bvrwh2"
   },
   "source": [
    "<font color='blue'> <b>Importing packages</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6ag91ijrQOs"
   },
   "outputs": [],
   "source": [
    "import numpy as np # importing numpy for numerical computation\n",
    "from sklearn.datasets import load_boston # here we are using sklearn's boston dataset\n",
    "from sklearn.metrics import mean_squared_error # importing mean_squared_error metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CcHOsONTt1K_"
   },
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "x=boston.data #independent variables\n",
    "y=boston.target #target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pc1htEFYuLRj",
    "outputId": "f5b60712-98b3-4cdc-b629-3546c1e3859c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "kQle3T_wuOa3",
    "outputId": "521c7bdd-5316-48d5-c534-b61d170d2c28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01,\n",
       "        6.5750e+00, 6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02,\n",
       "        1.5300e+01, 3.9690e+02, 4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9690e+02, 9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        7.1850e+00, 6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9283e+02, 4.0300e+00],\n",
       "       [3.2370e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        6.9980e+00, 4.5800e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9463e+02, 2.9400e+00],\n",
       "       [6.9050e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        7.1470e+00, 5.4200e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9690e+02, 5.3300e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEa_HqRZloH4"
   },
   "source": [
    "## <font color='red'><b>Task 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YQ5q8IxHNRk3"
   },
   "source": [
    "<font color='red'> <b>Step - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJCFCaOzl7Mr"
   },
   "source": [
    "*  <font color='blue'><b>Creating samples</b></font><br>\n",
    "    <b> Randomly create 30 samples from the whole boston data points</b>\n",
    "    *  Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points\n",
    "    \n",
    "     For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly , consider we have selected [4, 5, 7, 8, 9, 3] now we will replicate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]\n",
    "* <font color='blue'><b> Create 30 samples </b></font>\n",
    "    *  Note that as a part of the Bagging when you are taking the random samples <b>make sure each of the sample will have different set of columns</b><br>\n",
    "Ex: Assume we have 10 columns[1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10] for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample  [7, 9, 1, 4, 5, 6, 2] and so on...\n",
    "Make sure each sample will have atleast 3 feautres/columns/attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUqFEBSvNjCa"
   },
   "source": [
    "<font color='red'><b>Step - 2 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uqi9AhCYNq3Z"
   },
   "source": [
    "<font color='blue'><b>Building High Variance Models on each of the sample and finding train MSE value</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lLBnZHXOFln"
   },
   "source": [
    "*  Build a regression trees on each of 30 samples.\n",
    "*  Computed the predicted values of each data point(506 data points) in your corpus.\n",
    "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$\n",
    "*  Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kls23JLnSN23"
   },
   "source": [
    "<font color='red'> <b>Step - 3 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rz2GchkGSWnh"
   },
   "source": [
    "*  <font color='blue'><b>Calculating the OOB score </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DGHkVV2kSibm"
   },
   "source": [
    "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.\n",
    "*  Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK860ocxTyoz"
   },
   "source": [
    "# <font color='red'><b>Task 2</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dme-N6TUCrY"
   },
   "source": [
    "*  <font color='blue'><b>Computing CI of OOB Score and Train MSE</b></font>\n",
    "  *   Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n",
    "<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n",
    "<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n",
    "<li> you need to report CI of MSE and CI of OOB Score </li>\n",
    "<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O6UcH1x9Uwrj"
   },
   "source": [
    "# <font color='red'><b>Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bOC_AgsLU7OH"
   },
   "source": [
    "*  <font color='blue'><b>Given a single query point predict the price of house.</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HYs5jSFdVILe"
   },
   "source": [
    "Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] \n",
    "Predict the house price for this point as mentioned in the step 2 of Task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6gxZEsFWm-8"
   },
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V2fHTdS_zpgG"
   },
   "source": [
    "# <font color='blue'> <b>Task - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e0yGBuryOwHz"
   },
   "source": [
    "<font color='blue'><b>Step - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lJXX8vf3z073"
   },
   "source": [
    "*  <font color='blue'> <b>Creating samples</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CSVaWG1F4uCZ"
   },
   "source": [
    "<font color='Orange'><b>Algorithm</b></font>\n",
    "\n",
    "![alt text](https://i.imgur.com/BTVYXQ1.jpg/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_oWoN97BhDY"
   },
   "source": [
    "*  <font color='blue'><b> Write code for generating samples</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ph_6D2SDzz7F"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def generating_samples(input_data, target_data):\n",
    "    Selecting_row = np.random.choice(x.shape[0], size=303, replace=False, p=None)\n",
    "  \n",
    "    Replacing_rows = np.random.choice(Selecting_row.shape[0],size = 203, replace=False,p=None)\n",
    "    \n",
    "    Selecting_col = np.random.choice(x.shape[1],size = 5,replace=False, p =None)\n",
    "    \n",
    "    sample_data = input_data[Selecting_row[:,None],Selecting_col]\n",
    "    \n",
    "    target_of_sample_data = target_data[Selecting_row]\n",
    "    \n",
    "    Replicated_sample_data = sample_data[Replacing_rows]\n",
    "    target_of_replicated_sample_data = target_data[Replacing_rows]\n",
    "   \n",
    "    \n",
    "    final_sample_data = np.vstack((sample_data,Replicated_sample_data))\n",
    "    final_target_data = np.vstack(( target_of_sample_data.reshape(-1,1),target_of_replicated_sample_data.reshape(-1,1)))\n",
    "\n",
    "    '''In this function, we will write code for generating 30 samples '''\n",
    "    # you can use random.choice to generate random indices without replacement\n",
    "    # Please have a look at this link https://docs.scipy.org/doc/numpy-1.16.0/reference/generated/numpy.random.choice.html for more details\n",
    "    # Please follow above pseudo code for generating samples \n",
    "    \n",
    "\n",
    "    # return sampled_input_data , sampled_target_data,selected_rows,selected_columns\n",
    "    #note please return as lists\n",
    "    \n",
    "    return final_sample_data,final_target_data,Selecting_row,Selecting_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MivEQFlm7iOg"
   },
   "source": [
    "<font color='cyan'> <b> Grader function - 1 </b> </fongt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVvuhNzm7uld"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_samples(a,b,c,d):\n",
    "    length = (len(a)==506  and len(b)==506)\n",
    "    sampled = (len(a)-len(set([str(i) for i in a]))==203)\n",
    "    rows_length = (len(c)==303)\n",
    "    column_length= (len(d)>=3)\n",
    "    assert(length and sampled and rows_length and column_length)\n",
    "    return True\n",
    "a,b,c,d = generating_samples(x, y)\n",
    "grader_samples(a,b,c,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b4LSsmn4Jn2_"
   },
   "source": [
    "*  <font color='blue'> <b>Create 30 samples </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ec7MN6sL2BZ"
   },
   "source": [
    "![alt text](https://i.imgur.com/p8eZaWL.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XXlKWjCcBvTk"
   },
   "outputs": [],
   "source": [
    "# Use generating_samples function to create 30 samples \n",
    "# store these created samples in a list\n",
    "list_input_data =[]\n",
    "list_output_data =[]\n",
    "list_selected_row= []\n",
    "list_selected_columns=[]\n",
    "\n",
    "for i in range(0,30):\n",
    "    a,b,c,d = generating_samples(x,y)\n",
    "    list_input_data.append(a)\n",
    "    list_output_data.append(b)\n",
    "    list_selected_row.append(c)\n",
    "    list_selected_columns.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MXUz9VFiMQkh"
   },
   "source": [
    "<font color='cyan'> <b>Grader function - 2 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hCvIq8NuMWOC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_30(a):\n",
    "    assert(len(a)==30 and len(a[0])==506)\n",
    "    return True\n",
    "grader_30(list_input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Pv-mkZkO6dh"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "whaHCPB0O8qF"
   },
   "source": [
    "<font color='red'><b>Step - 2 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XBy4zXSWPtU8"
   },
   "source": [
    "<font color='orange'><b>Flowchart for building tree</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5xvH06HPQBdP"
   },
   "source": [
    "![alt text](https://i.imgur.com/pcXfSmp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRwPO_uHQjul"
   },
   "source": [
    "*  <font color='blue'><b> Write code for building regression trees</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "list_of_models = []\n",
    "for i in range(len(list_input_data)):\n",
    "    DT = DecisionTreeRegressor(max_depth=None)\n",
    "    DT.fit(list_input_data[i],list_output_data[i])\n",
    "    list_of_models.append(DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21j8BKfAQ1U8"
   },
   "source": [
    "<font color='orange'><b>Flowchart for calculating MSE </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Q0mTBD2RBx_"
   },
   "source": [
    "![alt text](https://i.imgur.com/sPEE618.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6e-UamlHRjPy"
   },
   "source": [
    "After getting predicted_y for each data point, we can use sklearns mean_squared_error to calculate the MSE between predicted_y and actual_y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TnIMT7_oR312"
   },
   "source": [
    "*  <font color='blue'><b> Write code for calculating MSE</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def predict(x, y, X):\n",
    "    rows = []\n",
    "    col = []\n",
    "    Y_pred = []\n",
    "    Y_sample=[]\n",
    "    \n",
    "    #regression trees on each of 30 samples\n",
    "    for i in range(30):\n",
    "        initial_sample = np.random.choice(x.shape[0],303,replace=False)\n",
    "        X_sample = x[initial_sample]\n",
    "        Y_sample=list(y[initial_sample])\n",
    "        rows.append(initial_sample)\n",
    "        \n",
    "        #replicating 203 data points from the sampled points\n",
    "        rep_sample = np.random.choice(initial_sample,203,replace=False)\n",
    "        for j in rep_sample:\n",
    "            X_sample = np.append(X_sample, x[j].reshape(1, -1), axis = 0)\n",
    "            Y_sample.append(y[j])\n",
    "        column = np.random.choice(13,13, replace = False)\n",
    "        X_sample = X_sample[:, column]\n",
    "        col.append(column)\n",
    "        \n",
    "        regressor = DecisionTreeRegressor()\n",
    "        regressor.fit(X_sample, Y_sample)\n",
    "        \n",
    "        pred = regressor.predict(x[:, column])\n",
    "        Y_pred.append(pred)\n",
    "    return rows, col, Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_error(x, y):  #calculating mse\n",
    "    rows, col, pred = predict(x, y, x)\n",
    "    pred = list(map(list, zip(*pred))) \n",
    "    y_pred = np.zeros(len(pred))\n",
    "    for i in range(len(pred)):\n",
    "        val = 0\n",
    "        for j in range(len(pred[0])):\n",
    "            val += pred[i][j]\n",
    "        val/=len(pred[0])\n",
    "        y_pred[i] = val\n",
    "    err = 0\n",
    "    for i in range(len(y)):\n",
    "        #calculating mse and updating\n",
    "        err += (y[i] - y_pred[i])**2\n",
    "    err/=len(y)\n",
    "    return err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7311174571804997\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "MSE = mse_error(x, y)\n",
    "print(MSE)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RuclPDMnSz8F"
   },
   "source": [
    "<font color='blue'><b>Step - 3 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESb9FSIDTM5V"
   },
   "source": [
    "<font color='orange'><b>Flowchart for calculating OOB score</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HB-d6NMETbd9"
   },
   "source": [
    "![alt text](https://i.imgur.com/95S5Mtm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WW3GOcFzTqbt"
   },
   "source": [
    "Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zBqcS03pUYSZ"
   },
   "source": [
    "*  <font color='blue'><b> Write code for calculating OOB score </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_of_bag(x, y):\n",
    "    rows, col, pred = predict(x, y, x)\n",
    "    pred = list(map(list, zip(*pred))) \n",
    "    y_pred = np.zeros(len(pred))\n",
    "    for i in range(len(pred)):\n",
    "        val = 0\n",
    "        c = 0\n",
    "        for j in range(len(pred[0])):\n",
    "            # for model which was buit on samples not included 𝑥𝑖\n",
    "            if i not in rows[j]:\n",
    "                val += pred[i][j]\n",
    "                c += 1\n",
    "        val/=c\n",
    "        y_pred[i] = val\n",
    "    err = 0\n",
    "    for i in range(len(y)):\n",
    "        err += (y[i] - y_pred[i])**2\n",
    "    err/=len(y)\n",
    "    return err\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Score: 12.01767504681578\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "oob = out_of_bag(x, y)\n",
    "print(\"OOB Score:\",oob)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sbuiwX3OUjUI"
   },
   "source": [
    "# <font color='blue'><b>Task 2</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval(x,y): #35 time doind task 1 step 2 and 3\n",
    "    mse_scores = []\n",
    "    oob_scores = []\n",
    "    for i in range(35):\n",
    "        mse_scores.append(mse_error(x,y))\n",
    "        oob_scores.append(out_of_bag(x, y))\n",
    "    return mse_scores,oob_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_scores,oob_scores = confidence_interval(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 95% confidence interval for population mean of MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+---------------------+-------------------+----------+-----------+-------+\n",
      "| #samples | Sample Size |    Sample mean     |      Sample std     |  Population mean  | Left C.I | Right C.I | Catch |\n",
      "+----------+-------------+--------------------+---------------------+-------------------+----------+-----------+-------+\n",
      "|    1     |      35     | 1.8617254476441434 |  0.1218705140496529 | 1.904861085388042 |  1.821   |   1.903   | False |\n",
      "|    2     |      35     | 1.9506166829788563 | 0.17302641297346746 | 1.904861085388042 |  1.892   |   2.009   |  True |\n",
      "|    3     |      35     | 1.8959207585168454 | 0.12610456718126364 | 1.904861085388042 |  1.853   |   1.939   |  True |\n",
      "|    4     |      35     | 1.896448176171654  | 0.13470356924464572 | 1.904861085388042 |  1.851   |   1.942   |  True |\n",
      "|    5     |      35     | 1.9044079672501413 | 0.14652380729271247 | 1.904861085388042 |  1.855   |   1.954   |  True |\n",
      "|    6     |      35     | 1.9151983543509625 | 0.13583868014260791 | 1.904861085388042 |  1.869   |   1.961   |  True |\n",
      "|    7     |      35     | 1.9476760762908591 | 0.15435841983602358 | 1.904861085388042 |  1.895   |    2.0    |  True |\n",
      "|    8     |      35     | 1.914970892778719  | 0.15611183014387217 | 1.904861085388042 |  1.862   |   1.968   |  True |\n",
      "|    9     |      35     | 1.933401972520233  | 0.13466450571772412 | 1.904861085388042 |  1.888   |   1.979   |  True |\n",
      "|    10    |      35     |  1.8891421695213   | 0.16275546283801884 | 1.904861085388042 |  1.834   |   1.944   |  True |\n",
      "+----------+-------------+--------------------+---------------------+-------------------+----------+-----------+-------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "mse_scores = np.asarray(mse_scores)\n",
    "x = PrettyTable()\n",
    "x = PrettyTable([\"#samples\", \"Sample Size\", \"Sample mean\", \"Sample std\", \"Population mean\",\"Left C.I\",\"Right C.I\",\"Catch\"])\n",
    "\n",
    "Population_mean = mse_scores.mean()\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    sample = mse_scores[np.random.choice(mse_scores.shape[0],size = 35)]\n",
    "    sample_size = len(sample)\n",
    "    sample_mean = sample.mean()\n",
    "    sample_std =  sample.std()\n",
    "\n",
    "    # here we are using sample standard deviation instead of population standard deviation\n",
    "    left_limit  = np.round(sample_mean - 2*(sample_std/np.sqrt(sample_size)), 3)\n",
    "    right_limit = np.round(sample_mean + 2*(sample_std/np.sqrt(sample_size)), 3)\n",
    "\n",
    "    row = []\n",
    "    row.append(i+1)\n",
    "    row.append(sample_size)\n",
    "    row.append(sample_mean)\n",
    "    row.append(sample_std)\n",
    "    row.append(Population_mean)\n",
    "    row.append(left_limit)\n",
    "    row.append(right_limit)\n",
    "    row.append((Population_mean <= right_limit) and (Population_mean >= left_limit))\n",
    "    x.add_row(row)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 95% Confidence interval for population mean of OOB Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+---------------------+-------------------+----------+-----------+-------+\n",
      "| #samples | Sample Size |    Sample mean     |      Sample std     |  Population mean  | Left C.I | Right C.I | Catch |\n",
      "+----------+-------------+--------------------+---------------------+-------------------+----------+-----------+-------+\n",
      "|    1     |      35     | 11.499289463472824 |  0.5356691752577091 | 11.44015025494142 |  11.318  |   11.68   |  True |\n",
      "|    2     |      35     | 11.557619987208183 |  0.5477566589153584 | 11.44015025494142 |  11.372  |   11.743  |  True |\n",
      "|    3     |      35     | 11.289023958326846 |  0.567196728680508  | 11.44015025494142 |  11.097  |   11.481  |  True |\n",
      "|    4     |      35     | 11.285517134985701 |  0.5149144530986104 | 11.44015025494142 |  11.111  |   11.46   |  True |\n",
      "|    5     |      35     | 11.441741044900661 |   0.62037834077587  | 11.44015025494142 |  11.232  |   11.651  |  True |\n",
      "|    6     |      35     | 11.46984126569317  |  0.5749351795270661 | 11.44015025494142 |  11.275  |   11.664  |  True |\n",
      "|    7     |      35     | 11.593901993782891 |  0.5553736579069644 | 11.44015025494142 |  11.406  |   11.782  |  True |\n",
      "|    8     |      35     | 11.343709266676672 |  0.5248975421718864 | 11.44015025494142 |  11.166  |   11.521  |  True |\n",
      "|    9     |      35     | 11.525966441015392 |  0.5688303390931292 | 11.44015025494142 |  11.334  |   11.718  |  True |\n",
      "|    10    |      35     | 11.53381556731988  | 0.48474104173927673 | 11.44015025494142 |  11.37   |   11.698  |  True |\n",
      "+----------+-------------+--------------------+---------------------+-------------------+----------+-----------+-------+\n"
     ]
    }
   ],
   "source": [
    "oob_scores = np.asarray(oob_scores)\n",
    "x = PrettyTable()\n",
    "x = PrettyTable([\"#samples\", \"Sample Size\", \"Sample mean\", \"Sample std\", \"Population mean\",\"Left C.I\",\"Right C.I\",\"Catch\"])\n",
    "\n",
    "Population_mean = oob_scores.mean()\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    sample = oob_scores[np.random.choice(oob_scores.shape[0],size = 35)]\n",
    "    sample_size = len(sample)\n",
    "    sample_mean = sample.mean()\n",
    "    sample_std =  sample.std()\n",
    "\n",
    "    # here we are using sample standard deviation instead of population standard deviation\n",
    "    left_limit  = np.round(sample_mean - 2*(sample_std/np.sqrt(sample_size)), 3)\n",
    "    right_limit = np.round(sample_mean + 2*(sample_std/np.sqrt(sample_size)), 3)\n",
    "\n",
    "    row = []\n",
    "    row.append(i+1)\n",
    "    row.append(sample_size)\n",
    "    row.append(sample_mean)\n",
    "    row.append(sample_std)\n",
    "    row.append(Population_mean)\n",
    "    row.append(left_limit)\n",
    "    row.append(right_limit)\n",
    "    row.append((Population_mean <= right_limit) and (Population_mean >= left_limit))\n",
    "    x.add_row(row)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKTnJdiBVS_e"
   },
   "source": [
    "# <font color='blue'><b>Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eXxrvZqHV1Fr"
   },
   "source": [
    "<font color='orange'><b>Flowchart for Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NyjwEJ62V6a6"
   },
   "source": [
    "<b>Hint: </b> We created 30 models by using 30 samples in TASK-1. Here, we need send query point \"xq\"  to 30 models and perform the regression on the output generated by 30 models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0emSwLL7VurD"
   },
   "source": [
    "![alt text](https://i.imgur.com/Y5cNhQk.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29hjwKlWWDfo"
   },
   "source": [
    "*  <font color='blue'><b> Write code for TASK 3 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_pUlSD-VYD1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted output for the given query point is  [22.16833333]\n"
     ]
    }
   ],
   "source": [
    "xq= np.array([0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60])\n",
    "\n",
    "predicted_value = 0\n",
    "\n",
    "for model in range(30):\n",
    "    predicted_value+=list_of_models[i].predict(xq[list_selected_columns[model]].reshape(1,-1))\n",
    "\n",
    "print(\"The predicted output for the given query point is \",predicted_value/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-0b175fab34b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#converting input to array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mxq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mpred_yq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The predicted house price for Xq is:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_yq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-c0adbc64b223>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(x, y, X)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# applying regression trees on each of 30 samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0minitial_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m303\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mX_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minitial_sample\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mY_sample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minitial_sample\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\prettytable\\prettytable.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    236\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: shape"
     ]
    }
   ],
   "source": [
    "xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60]\n",
    "#converting input to array\n",
    "xq = np.asarray(xq).reshape(1, -1)\n",
    "indices, col, Yq = predict(x, y, xq)\n",
    "pred_yq = sum(Yq)/len(Yq)\n",
    "print(\"The predicted house price for Xq is:\", pred_yq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DJHTGEZgWJjR"
   },
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IOdUi-0xWOJ9"
   },
   "source": [
    "<font color='red'><b>Write observations for task 1, task 2, task 3 indetail</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIcax45hWKT-"
   },
   "source": [
    "# Observations\n",
    "### Task -1\n",
    "\n",
    "   \n",
    "<li> We are randomly taking 60% of data and from that we again select 40% randomly, in result we get all 100 % of randomly sampled data points</li>\n",
    "    \n",
    "<li> we are doing both row sampling and column sampling(feature sampling) </li>\n",
    "    \n",
    "<li> We created 30 such samples and for each samples we are building a Decision Tree Regressor for each of our 30 samples with max depth i.e we are intentionally trying to overfit each of our tree by growing them to the maximum depth possible</li>\n",
    "    \n",
    "<li>We are  predicting house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$ and calculating the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$ </li>\n",
    "    \n",
    "<li>We are also predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$. and calculating the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$.</li>\n",
    "    </ul>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task- 2\n",
    "\n",
    "  <li> Here we are repeating task-1, 35 times and generating 35 such mse and obb scores</li>\n",
    "  \n",
    "  <li>Taking 10 random samples each of size 35 from our data and calculate their mean <font color='red'> $\\overline{x}$</font> and also thier standard deviation <font color='red'>$s$</font> </li>\n",
    "    <li> Now for as we using sample standard deviation instead of population standard deviation, we can take the standard error of mean or <font color='red' > SE mean </font>as  <font color='red'>$\\frac{s}{\\sqrt{n}}$</font> and calculate the 95% C.I as [<font color='red'> $\\overline{x}$- 2*$\\frac{s}{\\sqrt{n}}$, $\\overline{x}$+2*$\\frac{s}{\\sqrt{n}}$</font>]. We get <font color='red'> 10 </font> C.I , one for each sample.</li>\n",
    "    <li> True population mean must be in range for approximately 95 Confidence Intervals. So , for 10 samples , we might see 9 C.I's catching the Pop mean and we can observe that in our table</li>\n",
    "    <li> Doing this for both Obb and mse scores and we can see that 9 C.I's catching the Pop mean and we can observe that in our table</li>\n",
    "    <li> We know that If repeated random samples were taken and the 95% confidence interval was computed for each sample, 95% of the intervals would contain the population mean.</li>\n",
    "    \n",
    "   <li>Note: - 95% confidence interval does not eaxctly means that 95% of data lies in the gievn boundary. The exact meaning of that is if you are performing an experiment of taking samples from population and each sample have finite no.of observations and your keep on taking samples. Now 95% of times your population mean will fall in the confidence intervals calculated using the samples This statement has been justified by our experiment.</li>\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task-3\n",
    "\n",
    "<li>Considering xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] as our querry point and predicting the house price for this point as  $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$. </li>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bootstrap_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
